# 分布式搜索引擎

## Lucene

[Apache Lucene - Apache Lucene Core](https://lucene.apache.org/core/index.html)

[Lucene介绍与使用_就算你说晚上有太阳，我都不想辩解什么了-CSDN博客_lucene](https://blog.csdn.net/weixin_42633131/article/details/82873731)

[Lucene就是这么简单 - SegmentFault 思否](https://segmentfault.com/a/1190000013822385)

- Lucene是一套用于全文检索和搜寻的开源程序库，由Apache软件基金会支持和提供
- Lucene提供了一个简单却强大的应用程序接口（API），能够做全文索引和搜寻，在Java开发环境里Lucene是一个成熟的免费开放源代码工具
- Lucene并不是现成的搜索引擎产品，但可以用来制作搜索引擎产品

###  基本使用

#### 创建索引

#####  创建索引的流程

![在这里插入图片描述](https://img-blog.csdn.net/20180927203333130?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjYzMzEzMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

文档Document：数据库中一条具体的记录

字段Field：数据库中的每个字段

目录对象Directory：物理存储位置

写出器的配置对象：需要分词器和lucene的版本

##### 添加依赖

```xml
<properties>
    <lunece.version>4.10.2</lunece.version>
</properties>
<dependencies>
    <dependency>
        <groupId>junit</groupId>
        <artifactId>junit</artifactId>
        <version>4.12</version>
    </dependency>
    <!-- lucene核心库 -->
    <dependency>
        <groupId>org.apache.lucene</groupId>
        <artifactId>lucene-core</artifactId>
        <version>${lunece.version}</version>
    </dependency>
    <!-- Lucene的查询解析器 -->
    <dependency>
        <groupId>org.apache.lucene</groupId>
        <artifactId>lucene-queryparser</artifactId>
        <version>${lunece.version}</version>
    </dependency>
    <!-- lucene的默认分词器库 -->
    <dependency>
        <groupId>org.apache.lucene</groupId>
        <artifactId>lucene-analyzers-common</artifactId>
        <version>${lunece.version}</version>
    </dependency>
    <!-- lucene的高亮显示 -->
    <dependency>
        <groupId>org.apache.lucene</groupId>
        <artifactId>lucene-highlighter</artifactId>
        <version>${lunece.version}</version>
    </dependency>
</dependencies>
```

##### 代码实现

```
// 创建索引
    @Test
    public void testCreate() throws Exception{
        //1 创建文档对象
        Document document = new Document();
        // 创建并添加字段信息。参数：字段的名称、字段的值、是否存储，这里选Store.YES代表存储到文档列表。Store.NO代表不存储
        document.add(new StringField("id", "1", Field.Store.YES));
        // 这里我们title字段需要用TextField，即创建索引又会被分词。 
        document.add(new TextField("title", "谷歌地图之父跳槽facebook", Field.Store.YES));

        //2 索引目录类,指定索引在硬盘中的位置
        Directory directory = FSDirectory.open(new File("d:\\indexDir"));
        //3 创建分词器对象
        Analyzer analyzer = new StandardAnalyzer();
        //4 索引写出工具的配置对象
        IndexWriterConfig conf = new IndexWriterConfig(Version.LATEST, analyzer);
        //5 创建索引的写出工具类。参数：索引的目录和配置信息
        IndexWriter indexWriter = new IndexWriter(directory, conf);

        //6 把文档交给IndexWriter
        indexWriter.addDocument(document);
        //7 提交
        indexWriter.commit();
        //8 关闭
        indexWriter.close();
 }
```

##### 使用工具查看索引

##### 创建索引的API

###### Document（文档类）

Document：文档对象，是一条原始的数据

![在这里插入图片描述](https://img-blog.csdn.net/20180927203934608?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjYzMzEzMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

###### Field（字段类）

一个Document中可以有很多个不同的字段，每一个字段都是一个Field类的对象。

一个Document中的字段其类型是不确定的，因此Field类就提供了各种不同的子类，来对应这些不同类型的字段。

这些子类有一些不同的特性：

1）DoubleField、FloatField、IntField、LongField、StringField这些子类一定会被创建索引，但是不会被分词，而且不一定会被存储到文档列表。要通过构造函数中的参数Store来指定：如果Store.YES代表存储，Store.NO代表不存储

2）TextField即创建索引，又会被分词。StringField会创建索引，但是不会被分词。

如果不分词，会造成整个字段作为一个词条，除非用户完全匹配，否则搜索不到

3）StoreField一定会被存储，但是一定不创建索引

StoredField可以创建各种数据类型的字段

###### Directory（目录类）

指定索引要存储的位置

FSDirectory：文件系统目录，会把索引库指向本地磁盘。

```
特点：速度略慢，但是比较安全
```

RAMDirectory：内存目录，会把索引库保存在内存。

```
特点：速度快，但是不安全
```

###### Analyzer（分词器类）

提供分词算法，可以把文档中的数据按照算法分词

合适的中文分词器一般我们用IK分词器。

```java
    <dependency>
    
      <groupId>com.janeluo</groupId>
    
      <artifactId>ikanalyzer</artifactId>
    
      <version>2012_u6</version>
    
    </dependency>
```

###### IndexWriterConfig（索引写出器配置类）

1） 设置配置信息：Lucene的版本和分词器类型

2）设置是否清空索引库中的数据

###### IndexWriter（索引写出器类）

- 索引写出工具，作用就是 实现对索引的增（创建索引）、删（删除索引）、改（修改索引）
- 可以一次创建一个，也可以批量创建索引

#### 查询索引数据

##### 代码实现

```java
@Test
    public void testSearch() throws Exception {
        // 索引目录对象
        Directory directory = FSDirectory.open(new File("d:\\indexDir"));
        // 索引读取工具
        IndexReader reader = DirectoryReader.open(directory);
        // 索引搜索工具
        IndexSearcher searcher = new IndexSearcher(reader);
        // 创建查询解析器,两个参数：默认要查询的字段的名称，分词器
        QueryParser parser = new QueryParser("title", new IKAnalyzer());
        // 创建查询对象
        Query query = parser.parse("谷歌");
        // 搜索数据,两个参数：查询条件对象要查询的最大结果条数
        // 返回的结果是 按照匹配度排名得分前N名的文档信息（包含查询到的总条数信息、所有符合条件的文档的编号信息）。
        TopDocs topDocs = searcher.search(query, 10);
        // 获取总条数
        System.out.println("本次搜索共找到" + topDocs.totalHits + "条数据");
        // 获取得分文档对象（ScoreDoc）数组.SocreDoc中包含：文档的编号、文档的得分
        ScoreDoc[] scoreDocs = topDocs.scoreDocs;
        for (ScoreDoc scoreDoc : scoreDocs) {
            // 取出文档编号
            int docID = scoreDoc.doc;
            // 根据编号去找文档
            Document doc = reader.document(docID);
            System.out.println("id: " + doc.get("id"));
            System.out.println("title: " + doc.get("title"));
            // 取出文档得分
            System.out.println("得分： " + scoreDoc.score);
        }
    }
```

##### 核心API

###### QueryParser（查询解析器）

1）QueryParser（单一字段的查询解析器）

2）MultiFieldQueryParser（多字段的查询解析器）

###### Query（查询对象，包含要查询的关键词信息）

1）通过QueryParser解析关键字，得到查询对象

2）自定义查询对象（高级查询）

###### IndexSearch（索引搜索对象，执行搜索功能）

IndexSearch可以帮助我们实现：快速搜索、排序、打分等功能。

IndexSearch需要依赖IndexReader类

###### TopDocs（查询结果对象）

过IndexSearcher对象，我们可以搜索，获取结果：TopDocs对象

在TopDocs中，包含两部分信息：

```
int totalHits：查询到的总条数
ScoreDoc[] scoreDocs：得分文档对象的数组
```

######  ScoreDoc(得分文档对象)

ScoreDoc是得分文档对象，包含两部分数据：

```
int doc：文档的编号----lucene给文档的一个唯一编号
float score：文档的得分信息
拿到编号后，我们还需要根据编号来获取真正的文档信息
```

##### 特殊查询

```java
public void search(Query query) throws Exception {
        // 索引目录对象
        Directory directory = FSDirectory.open(new File("indexDir"));
        // 索引读取工具
        IndexReader reader = DirectoryReader.open(directory);
        // 索引搜索工具
        IndexSearcher searcher = new IndexSearcher(reader);

        // 搜索数据,两个参数：查询条件对象要查询的最大结果条数
        // 返回的结果是 按照匹配度排名得分前N名的文档信息（包含查询到的总条数信息、所有符合条件的文档的编号信息）。
        TopDocs topDocs = searcher.search(query, 10);
        // 获取总条数
        System.out.println("本次搜索共找到" + topDocs.totalHits + "条数据");
        // 获取得分文档对象（ScoreDoc）数组.SocreDoc中包含：文档的编号、文档的得分
        ScoreDoc[] scoreDocs = topDocs.scoreDocs;

        for (ScoreDoc scoreDoc : scoreDocs) {
            // 取出文档编号
            int docID = scoreDoc.doc;
            // 根据编号去找文档
            Document doc = reader.document(docID);
            System.out.println("id: " + doc.get("id"));
            System.out.println("title: " + doc.get("title"));
            // 取出文档得分
            System.out.println("得分： " + scoreDoc.score);
        }
    }
```

###### TermQuery（词条查询）

```java
/*
     * 测试普通词条查询
     * 注意：Term(词条)是搜索的最小单位，不可再分词。值必须是字符串！
     */
    @Test
    public void testTermQuery() throws Exception {
        // 创建词条查询对象
        Query query = new TermQuery(new Term("title", "谷歌地图"));
        search(query);
    }
```

###### WildcardQuery（通配符查询）

```
/*
     * 测试通配符查询
     * 	? 可以代表任意一个字符
     * 	* 可以任意多个任意字符
     */
    @Test
    public void testWildCardQuery() throws Exception {
        // 创建查询对象
        Query query = new WildcardQuery(new Term("title", "*歌*"));
        search(query);
    }
```

###### FuzzyQuery（模糊查询）

```java
 /*
     * 测试模糊查询
     */
    @Test
    public void testFuzzyQuery() throws Exception {
        // 创建模糊查询对象:允许用户输错。但是要求错误的最大编辑距离不能超过2
        // 编辑距离：一个单词到另一个单词最少要修改的次数 facebool --> facebook 需要编辑1次，编辑距离就是1
//    Query query = new FuzzyQuery(new Term("title","fscevool"));
        // 可以手动指定编辑距离，但是参数必须在0~2之间
        Query query = new FuzzyQuery(new Term("title","facevool"),1);
        search(query);
    }
```

###### NumericRangeQuery（数值范围查询）

```java
/*
	 * 测试：数值范围查询
	 * 注意：数值范围查询，可以用来对非String类型的ID进行精确的查找
	 */
	@Test
	public void testNumericRangeQuery() throws Exception{
		// 数值范围查询对象，参数：字段名称，最小值、最大值、是否包含最小值、是否包含最大值
		Query query = NumericRangeQuery.newLongRange("id", 2L, 2L, true, true);
		search(query);
	}
```

###### BooleanQuery（组合查询）

```java
 /*
     * 布尔查询：
     * 	布尔查询本身没有查询条件，可以把其它查询通过逻辑运算进行组合！
     * 交集：Occur.MUST + Occur.MUST
     * 并集：Occur.SHOULD + Occur.SHOULD
     * 非：Occur.MUST_NOT
     */
    @Test
    public void testBooleanQuery() throws Exception{

        Query query1 = NumericRangeQuery.newLongRange("id", 1L, 3L, true, true);
        Query query2 = NumericRangeQuery.newLongRange("id", 2L, 4L, true, true);
        // 创建布尔查询的对象
        BooleanQuery query = new BooleanQuery();
        // 组合其它查询
        query.add(query1, BooleanClause.Occur.MUST_NOT);
        query.add(query2, BooleanClause.Occur.SHOULD);
        search(query);
    }
```

##### 修改索引

```java
/* 测试：修改索引
     * 注意：
     * 	A：Lucene修改功能底层会先删除，再把新的文档添加。
     * 	B：修改功能会根据Term进行匹配，所有匹配到的都会被删除。这样不好
     * 	C：因此，一般我们修改时，都会根据一个唯一不重复字段进行匹配修改。例如ID
     * 	D：但是词条搜索，要求ID必须是字符串。如果不是，这个方法就不能用。
     * 如果ID是数值类型，我们不能直接去修改。可以先手动删除deleteDocuments(数值范围查询锁定ID)，再添加。
     */
@Test
public void testUpdate() throws Exception{
    // 创建目录对象
    Directory directory = FSDirectory.open(new File("indexDir"));
    // 创建配置对象
    IndexWriterConfig conf = new IndexWriterConfig(Version.LATEST, new IKAnalyzer());
    // 创建索引写出工具
    IndexWriter writer = new IndexWriter(directory, conf);

    // 创建新的文档数据
    Document doc = new Document();
    doc.add(new StringField("id","1",Store.YES));
    doc.add(new TextField("title","谷歌地图之父跳槽facebook ",Store.YES));
    /* 修改索引。参数：
         * 	词条：根据这个词条匹配到的所有文档都会被修改
         * 	文档信息：要修改的新的文档数据
         */
    writer.updateDocument(new Term("id","1"), doc);
    // 提交
    writer.commit();
    // 关闭
    writer.close();
}
```

##### 删除索引

```java
/*
     * 演示：删除索引
     * 注意：
     * 	一般，为了进行精确删除，我们会根据唯一字段来删除。比如ID
     * 	如果是用Term删除，要求ID也必须是字符串类型！
     */
@Test
public void testDelete() throws Exception {
    // 创建目录对象
    Directory directory = FSDirectory.open(new File("indexDir"));
    // 创建配置对象
    IndexWriterConfig conf = new IndexWriterConfig(Version.LATEST, new IKAnalyzer());
    // 创建索引写出工具
    IndexWriter writer = new IndexWriter(directory, conf);
    // 根据词条进行删除
    //		writer.deleteDocuments(new Term("id", "1"));

    // 根据query对象删除,如果ID是数值类型，那么我们可以用数值范围查询锁定一个具体的ID
    //		Query query = NumericRangeQuery.newLongRange("id", 2L, 2L, true, true);
    //		writer.deleteDocuments(query);
    // 删除所有
    writer.deleteAll();
    // 提交
    writer.commit();
    // 关闭
    writer.close();
}
```

#### 高级使用

##### 高亮显示

1）给所有关键字加上一个HTML标签

2）给这个特殊的标签设置CSS样式

```java
// 高亮显示
    @Test
    public void testHighlighter() throws Exception {
        // 目录对象
        Directory directory = FSDirectory.open(new File("indexDir"));
        // 创建读取工具
        IndexReader reader = DirectoryReader.open(directory);
        // 创建搜索工具
        IndexSearcher searcher = new IndexSearcher(reader);
        QueryParser parser = new QueryParser("title", new IKAnalyzer());
        Query query = parser.parse("谷歌地图");
        // 格式化器
        Formatter formatter = new SimpleHTMLFormatter("<em>", "</em>");
        QueryScorer scorer = new QueryScorer(query);
        // 准备高亮工具
        Highlighter highlighter = new Highlighter(formatter, scorer);
        // 搜索
        TopDocs topDocs = searcher.search(query, 10);
        System.out.println("本次搜索共" + topDocs.totalHits + "条数据");
        ScoreDoc[] scoreDocs = topDocs.scoreDocs;
        for (ScoreDoc scoreDoc : scoreDocs) {
            // 获取文档编号
            int docID = scoreDoc.doc;
            Document doc = reader.document(docID);
            System.out.println("id: " + doc.get("id"));
            String title = doc.get("title");
            // 用高亮工具处理普通的查询结果,参数：分词器，要高亮的字段的名称，高亮字段的原始值
            String hTitle = highlighter.getBestFragment(new IKAnalyzer(), "title", title);
            System.out.println("title: " + hTitle);
            // 获取文档的得分
            System.out.println("得分：" + scoreDoc.score);
        }
    }
```

##### 排序

```java
// 排序
    @Test
    public void testSortQuery() throws Exception {
        // 目录对象
        Directory directory = FSDirectory.open(new File("indexDir"));
        // 创建读取工具
        IndexReader reader = DirectoryReader.open(directory);
        // 创建搜索工具
        IndexSearcher searcher = new IndexSearcher(reader);
        QueryParser parser = new QueryParser("title", new IKAnalyzer());
        Query query = parser.parse("谷歌地图");
        // 创建排序对象,需要排序字段SortField，参数：字段的名称、字段的类型、是否反转如果是false，升序。true降序
        Sort sort = new Sort(new SortField("id", SortField.Type.LONG, true));
        // 搜索
        TopDocs topDocs = searcher.search(query, 10,sort);
        System.out.println("本次搜索共" + topDocs.totalHits + "条数据");
        ScoreDoc[] scoreDocs = topDocs.scoreDocs;
        for (ScoreDoc scoreDoc : scoreDocs) {
            // 获取文档编号
            int docID = scoreDoc.doc;
            Document doc = reader.document(docID);
            System.out.println("id: " + doc.get("id"));
            System.out.println("title: " + doc.get("title"));
        }
    }
```

##### 分页

```java
// 分页
	@Test
	public void testPageQuery() throws Exception {
		// 实际上Lucene本身不支持分页。因此我们需要自己进行逻辑分页。我们要准备分页参数：
		int pageSize = 2;// 每页条数
		int pageNum = 3;// 当前页码
		int start = (pageNum - 1) * pageSize;// 当前页的起始条数
		int end = start + pageSize;// 当前页的结束条数（不能包含）
		// 目录对象
		Directory directory = FSDirectory.open(new File("indexDir"));
		// 创建读取工具
		IndexReader reader = DirectoryReader.open(directory);
		// 创建搜索工具
		IndexSearcher searcher = new IndexSearcher(reader);
		QueryParser parser = new QueryParser("title", new IKAnalyzer());
		Query query = parser.parse("谷歌地图");
		// 创建排序对象,需要排序字段SortField，参数：字段的名称、字段的类型、是否反转如果是false，升序。true降序
		Sort sort = new Sort(new SortField("id", Type.LONG, false));
		// 搜索数据，查询0~end条
		TopDocs topDocs = searcher.search(query, end,sort);
		System.out.println("本次搜索共" + topDocs.totalHits + "条数据");
		ScoreDoc[] scoreDocs = topDocs.scoreDocs;
		for (int i = start; i < end; i++) {
			ScoreDoc scoreDoc = scoreDocs[i];
			// 获取文档编号
			int docID = scoreDoc.doc;
			Document doc = reader.document(docID);
			System.out.println("id: " + doc.get("id"));
			System.out.println("title: " + doc.get("title"));
		}
	}
```

##### 得分算法

Lucene会对搜索结果打分，用来表示文档数据与词条关联性的强弱，得分越高，表示查询的匹配度就越高，排名就越靠前。

## Solr

[Apache Solr -](https://lucene.apache.org/solr/)

[Solr的原理及使用 - 橘子洲头。 - 博客园 (cnblogs.com)](https://www.cnblogs.com/ericz2j/p/11118454.html)

[Solr的基本使用_happy_meng-CSDN博客_solr](https://blog.csdn.net/happy_meng/article/details/79129061)

Solr是一个独立的企业级搜索应用服务器，它对外提供类似于Web-service的API接口。用户可以通过http请求，向搜索引擎服务器提交一定格式的XML文件，生成索引；也可以通过Http Get操作提出查找请求，并得到XML格式的返回结果。

solr是基于Lucence开发的企业级搜索引擎技术

### 使用SolrJ管理索引库

#### 添加文档

```
public voidtestSolrJAdd() throws SolrServerException, IOException {
// 创建一个SolrServer对象。创建一个HttpSolrServer对象
// 需要指定solr服务的url
SolrServer solrServer = newHttpSolrServer( "http://101.132.69.111:8080/solr/collection1");
// 创建一个文档对象SolrInputDocument
SolrInputDocument document= newSolrInputDocument();
// 向文档中添加域，必须有id域，域的名称必须在schema.xml中定义
document.addField( "id", "123");
document.addField( "item_title", "红米手机");
document.addField( "item_price", 1000);
// 把文档对象写入索引库
solrServer.add( document);
// 提交
solrServer.commit();
}
```

#### 配置

schema.xml，在SolrCore的conf目录下，它是Solr数据表配置文件，它定义了加入索引的数据的数据类型的。主要包括FieldTypes、Fields和其他的一些缺省设置。

field：进行索引，需要创建document，document中包括 了很多的field（域）。
field属性：是否索引、是否存储、是否分词 ，是否多值multiValued

multiValued：该Field如果要存储多个值时设置为true，solr允许一个Field存储多个值，比如存储一个用户的好友id（多个），商品的图片（多个，大图和小图），通过使用solr查询要看出返回给客户端是数组：

Fieldtype：在solr中对每个Field都有一个Type类型。

在Solr中进行索引、搜索时需要用哪些field需要提前在schema.xml文件中定义。

#### 删除文档

根据id删除

```
publicvoiddeleteDocumentById()throwsException {
SolrServer solrServer = newHttpSolrServer( "http://101.132.69.111:8080/solr/collection1");
solrServer.deleteById( "123");
// 提交
solrServer.commit();
}
```

根据查询删除

```
publicvoiddeleteDocumentByQuery()throwsException {
SolrServer solrServer = newHttpSolrServer( "http://101.132.69.111:8080/solr/collection1");
//根据分词去删
solrServer.deleteByQuery( "item_title:红米手机");
solrServer.commit();
}
```

#### 查询索引库

3.3.1 简单查询

```
publicvoidqueryDocument() throws Exception {
// 第一步：创建一个SolrServer对象
SolrServer solrServer = newHttpSolrServer( "http://101.132.69.111:8080/solr/collection1");
// 第二步：创建一个SolrQuery对象。
SolrQuery query = newSolrQuery();
// 第三步：向SolrQuery中添加查询条件、过滤条件。。。
query.setQuery( "*:*");
// 第四步：执行查询。得到一个Response对象。
QueryResponse response = solrServer.query(query);
// 第五步：取查询结果。
SolrDocumentList solrDocumentList = response.getResults();
System. out.println( "查询结果的总记录数："+ solrDocumentList.getNumFound());
// 第六步：遍历结果并打印。
for(SolrDocument solrDocument : solrDocumentList) {
System. out.println(solrDocument. get( "id"));
System. out.println(solrDocument. get( "item_title"));
System. out.println(solrDocument. get( "item_price"));
}
}
```

带高亮显示

```
public voidsearchDocumet() throws Exception {
// 创建一个SolrServer对象
SolrServer solrServer = newHttpSolrServer( "http://101.132.69.111:8080/solr/collection1");
// 创建一个SolrQuery对象
SolrQuery query = newSolrQuery();
// 设置查询条件、过滤条件、分页条件、排序条件、高亮
// query.set("q", "*:*");
query.setQuery( "手机");
// 分页条件
query.setStart( 0);
query.setRows( 30);
// 设置默认搜索域
query. set( "df", "item_keywords");
// 设置高亮
query.setHighlight( true);
// 高亮显示的域
query.addHighlightField( "item_title");
query.setHighlightSimplePre( "<div>");
query.setHighlightSimplePost( "</div>");
// 执行查询，得到一个Response对象
QueryResponse response = solrServer.query(query);
// 取查询结果
SolrDocumentList solrDocumentList = response.getResults();
// 取查询结果总记录数
System.out.println( "查询结果总记录数："+ solrDocumentList.getNumFound());
for(SolrDocument solrDocument : solrDocumentList) {
System.out.println(solrDocument. get( "id"));
// 取高亮显示
Map< String, Map< String, List< String>>> highlighting = response.getHighlighting();
List< String> list = highlighting. get(solrDocument. get( "id")). get( "item_title");
StringitemTitle = "";
if(list != null&& list.size() > 0) {
itemTitle = list. get( 0);
} else{
36itemTitle = ( String) solrDocument. get( "item_title");
}
System.out.println(itemTitle);
System.out.println(solrDocument. get( "item_sell_point"));
System.out.println(solrDocument. get( "item_price"));
System.out.println(solrDocument. get( "item_image"));
System.out.println(solrDocument. get( "item_category_name"));
}
```

## Elasticsearch7.x

[Elasticsearch：官方分布式搜索和分析引擎 | Elastic](https://www.elastic.co/cn/elasticsearch/)

[Elastic 中文社区 (elasticsearch.cn)](https://elasticsearch.cn/)

[ElasticSearch原理 - 神一样的存在 - 博客园 (cnblogs.com)](https://www.cnblogs.com/dreamroute/p/8484457.html)

[Elasticsearch-7.x学习笔记_ChengYanan的博客-CSDN博客](https://blog.csdn.net/qq_26502245/article/details/95607656)

[SpringBoot集成Elasticsearch7.4 实战（一） - 简书 (jianshu.com)](https://www.jianshu.com/p/1fbfde2aefa5)

![img](https://upload-images.jianshu.io/upload_images/16177192-0b8d299c65a51f20.png)

Elasticsearch 是一个分布式可扩展的实时搜索和分析引擎,一个建立在全文搜索引擎 Apache Lucene(TM) 基础上的搜索引擎.当然 Elasticsearch 并不仅仅是 Lucene 那么简单，它不仅包括了全文搜索功能，还可以进行以下工作:

- 分布式实时文件存储，并将每一个字段都编入索引，使其可以被搜索。
- 实时分析的分布式搜索引擎。
- 可以扩展到上百台服务器，处理PB级别的结构化或非结构化数据。

### 基础

Elasticsearch的文件存储，Elasticsearch是面向文档型数据库，一条数据在这里就是一个文档，用JSON作为文档序列化的格式，比如下面这条用户数据：

```
{
    "name" : "John",
    "sex" : "Male",
    "age" : 25,
    "birthDate" : "1990/05/01",
    "about" : "I love to go rock climbing",
    "interests" : [ "sports", "music" ]
}
```

用Mysql这样的数据库存储就会容易想到建立一张User表，有字段，在Elasticsearch里这就是一个*文档*，当然这个文档会属于一个User的*类型*，各种各样的类型存在于一个*索引*当中。这里有一份简易的将Elasticsearch和关系型数据术语对照表:

```
关系数据库 ⇒ 数据库 ⇒ 表 ⇒ 行 ⇒ 列(Columns)
Elasticsearch ⇒ 索引(Index) ⇒ 类型(type) ⇒ 文档(Docments) ⇒ 字段(Fields)  
```

一个 Elasticsearch 集群可以包含多个索引(数据库)，也就是说其中包含了很多类型(表)。这些类型中包含了很多的文档(行)，然后每个文档中又包含了很多的字段(列)。Elasticsearch的交互，可以使用Java API，也可以直接使用HTTP的Restful API方式，比如我们打算插入一条记录，可以简单发送一个HTTP的请求：

```
PUT /megacorp/employee/1  
{
    "name" : "John",
    "sex" : "Male",
    "age" : 25,
    "about" : "I love to go rock climbing",
    "interests": [ "sports", "music" ]
}
```

### 索引

为了提高搜索的性能，难免会牺牲某些其他方面，比如插入/更新。前面看到往Elasticsearch里插入一条记录，其实就是直接PUT一个json的对象，这个对象有多个fields，比如上面例子中的*name, sex, age, about, interests*，那么在插入这些数据到Elasticsearch的同时，Elasticsearch还默默的为这些字段建立索引--倒排索引，因为Elasticsearch最核心功能是搜索。

## Elasic Stack

[Elastic Stack入门_单人影的博客-CSDN博客_elastic stack](https://blog.csdn.net/a185589690/article/details/100852581)

ELK是三款软件的简称，分别是ElasticsearchLogstash、Kibana组成，在发展的过程中，又有新成员Beats的加入，所以就形成了Elastic Stack。所以说，ELK是旧的称呼，Elastic Stack是新的名字。

![img](https://img-blog.csdnimg.cn/20190915133109966.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExODU1ODk2OTA=,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/20190915133236468.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2ExODU1ODk2OTA=,size_16,color_FFFFFF,t_70)

### Elasticsearch

Elasticsearch 基于java，是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索 引副本机制，restful风格接口，多数据源，自动搜索负载等。

### Logstash

Logstash 基于java，是一个开源的用于收集,分析和存储日志的工具。

### Kibana

Kibana 基于nodejs，也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的 Web 界面，可以汇总、分析和搜索重要数据日志。

### Beats

Beats是elastic公司开源的一款采集系统监控数据的代理agent，是在被监控服务器上以客户端形式运行的数据收集器的统称，可以直接把数据发送给Elasticsearch或者通过Logstash发送给Elasticsearch，然后进行后续的数据分析活动。

Beats由如下组成:

- Packetbeat：是一个网络数据包分析器，用于监控、收集网络流量信息，Packetbeat嗅探服务器之间的流 量，解析应用层协议，并关联到消息的处理，其支 持ICMP (v4 and v6)、DNS、HTTP、Mysql、PostgreSQL、Redis、MongoDB、Memcache等协议；
- Filebeat：用于监控、收集服务器日志文件，其已取代 logstash forwarder；
- Metricbeat：可定期获取外部系统的监控指标信息，其可以监控、收集 Apache、HAProxy、MongoDB
- MySQL、Nginx、PostgreSQL、Redis、System、Zookeeper等服务；
- Winlogbeat：用于监控、收集Windows系统的日志信息；

### 基本概念

#### 索引

- ```
  1.索引（index）是Elasticsearch对逻辑数据的逻辑存储，所以它可以分为更小的部分。
  2.可以把索引看成关系型数据库的表，索引的结构是为快速有效的全文索引准备的，特别是它不存储原始值。
  3.可以把Elasticsearch的索引看成MongoDB里的一个集合。
  4.Elasticsearch可以把索引存放在一台机器或者分散在多台服务器上，每个索引有一或多个分片（shard）,每个分片可以有多个副本（replica）。
  ```

#### 文档

- ```
  1.存储在Elasticsearch中的主要实体叫文档（document）。用关系型数据库来类比的话，一个文档相当于数据库表中的一行记录。
  2.Elasticsearch和MongoDB中的文档类似，都可以有不同的结构，但Elasticsearch的文档中，相同字段必须有相同类型。
  3.文档由多个字段组成，每个字段可能多次出现在一个文档里，这样的字段叫多值字段（multivalued）。
  4.每个字段的类型，可以是文本、数值、日期等。字段类型也可以是复杂类型，一个字段包含其他子文档或者数组。
  ```

#### 映射

- ```
  所有文档写进索引之前都会先进行分析，如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做映射（mapping）。一般由用户自己定义规则。
  ```

#### 文档类型

- ```
  1.在Elasticsearch中，一个索引对象可以存储很多不同用途的对象。例如，一个博客应用程序可以保存文章和评论。
  2.每个文档可以有不同的结构。
  3.不同的文档类型不能为相同的属性设置不同的类型。例如，在同一索引中的所有文档类型中，一个叫title的字段必须具有相同的类型。
  ```

   