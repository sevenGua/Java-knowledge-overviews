# 大型分布式系统缓存架构进阶

## 缓存的种类

[认识缓存之客户端缓存_yipianye0510的博客-CSDN博客_客户端缓存](https://blog.csdn.net/yipianye0510/article/details/79694606)

### 客户端缓存

 缓存的最后一层，是直接面对客户端的客户端缓存。通常也把这部分称为web缓存。web缓存位于客户端。缓存会根据进来的请求保存输出内容的复本，例如html页面、图片文件等，然后，当下一个请求来到时，如果是相同的URL，缓存直接使用复本相应请求访问，而不是向源服务器再次发送请求。

  web缓存的具体实现是由浏览器来实现的。浏览器在计算机上开辟一块磁盘空间用于存储已经看过的网站的副本。浏览器缓存根据非常简单的规则进行工作：在同一个会话过程中会检查一次并确定缓存的复本足够新。这个缓存对于用户单击后退或者单击刚访问过的连接特别有用，如果你浏览过程中访问到同一个图片，这些图片可以从浏览器缓存中调用并即时显现。

前段页面缓存主要遵循HTTP协议和客户端的设置工作。

**1、不会缓存的情况如下：**

- 如果相应头信息告诉缓存器不要保留缓存，缓存器就不会缓存相应内容。
- 如果请求信息需要认证或者加密安全，相应内容也不会缓存。
- 如果在回应中不存在校验器（ETag或者Last-Modified头信息），缓存服务器会认为缺乏直接的更新度信息，内容会被认为不可缓存。

**2、将会缓存的情况如下：**

- 含有完整的过期时间和寿命控制头信息，并且内容扔在保鲜期内。
- 浏览器已经使用过缓存副本，并且在一个会话中已经检验过内容的新鲜度。
- 缓存代理服务器近期内已经使用过缓存副本，并且内容的最后更新时间在上次使用期之前。
- 够新的副本将直接从缓存中送出，而不会向源服务器发送请求。
- 如果缓存的副本已经太旧了，缓存服务器将向源服务器发出校验请求，用于确定是否可以继续使用当前拷贝继续服务。

### 网络缓存

[缓存：网络中的缓存。_孤芳不自赏-CSDN博客](https://blog.csdn.net/en_joker/article/details/102986240)

网络中的缓存位于客户端和服务端之间，代理或响应客户端的网络请求，从而对重复的请求返回缓存中的数据资源。同时，接受服务端的请求，更新缓存中的内容。

Web代理几乎是伴随着互联网诞生的，常用的Web代理分为正向代理、反向代理和透明代理。Web代理是将Web代理作为缓存的一种技术。

一般情况下，Web代理默认说的是正向代理，如下图所示。

![img](https://img-blog.csdnimg.cn/20191109152716536.png)

### 服务器端缓存

[服务器缓存(Cache)_龚韬的专栏-CSDN博客_服务器缓存](https://blog.csdn.net/gtncwy/article/details/80758511)

缓存指的是将需要频繁访问的网络内容存放在离用户较近、访问速度更快的系统中，以提高内容访问速度的一种技术。

服务器缓存工作原理

![img](https://img-blog.csdn.net/20180621120822353?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2d0bmN3eQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)

比较常见的模式有分为两大类： Cache-aside 以及 Cache-as-SoR。其中 Cache-as-SoR(System of Record, 即直接存储数据的DB) 又包括 Read-through、Write-through、Write-behind。

#### Cache-aside

Cache-aside 是比较通用的缓存模式，在这种模式，读数据的流程可以概括：

1. 读 cache，如果 cache 存在，直接返回。如果不存在，则执行2
2. 读 SoR，然后更新 cache，返回

#### Cache-as-SoR

在 Cache-aside 模式下，cache 的维护逻辑要业务端自己实现和维护，而 Cache-as-SoR 则是将 cache 的逻辑放在存储端，即 db + cache 对于业务调用方而言是透明的一个整体，业务无须关心实现细节，只需 get/set 即可。Cache-as-SoR 模式常见的有 Read Through、Write Through、Write Behind。

- Read Through: 发生读操作时，查询 cache，如果 Miss，则由 cache 查询 SoR 并更新，下次访问 cache 即可直接访问（即在存储端实现 cacha-aside）
- Write Through：发生写操作时，查询 cache，如果 Hit，则更新 cache，然后交由 cache model 去更新 SoR
- Write Behind：发生写操作时，不立即更新 SoR，只更新缓存，然后立即返回，同时异步的更新 SoR（最终一致）

Read/Write Through模式比较好理解，就是同步的更新 cache 和 SoR，读取得场景也是 cache 优先，miss 后才读 SoR。这类模式主要意义在意缓解读操作的场景下 SoR 的压力以及提升整体响应速度，对写操作并没有什么优化，适用于读多写少的场景。Write Behind 的的 cache 和 SoR 的更新是异步，可以在异步的时候通过 batch、merge 的方式优化写操作，所以能提升写操作的性能。

## Ehcache

[Ehcache 入门详解 （转） - myseries - 博客园 (cnblogs.com)](https://www.cnblogs.com/myseries/p/11370109.html)

### 基本介绍

EhCache 是一个纯Java的进程内缓存框架，具有快速、精干等特点，是Hibernate中默认CacheProvider。Ehcache是一种广泛使用的开源Java分布式缓存。主要面向通用缓存,Java EE和轻量级容器。它具有内存和磁盘存储，缓存加载器,缓存扩展,缓存异常处理程序,一个gzip缓存servlet过滤器,支持REST和SOAP api等特点。

Spring 提供了对缓存功能的抽象：即允许绑定不同的缓存解决方案（如Ehcache），但本身不直接提供缓存功能的实现。它支持注解方式使用缓存，非常方便。

### 主要的特性

1. 快速
2. 简单
3. 多种缓存策略
4. 缓存数据有两级：内存和磁盘，因此无需担心容量问题
5. 缓存数据会在虚拟机重启的过程中写入磁盘
6. 可以通过RMI、可插入API等方式进行分布式缓存
7. 具有缓存和缓存管理器的侦听接口
8. 支持多缓存管理器实例，以及一个实例的多个缓存区域
9. 提供Hibernate的缓存实现

### 集成

　　可以单独使用，一般在第三方库中被用到的比较多（如mybatis、shiro等）ehcache 对分布式支持不够好，多个节点不能同步，通常和redis一块使用

### ehcache 和 redis 比较

　　ehcache直接在jvm虚拟机中缓存，速度快，效率高；但是缓存共享麻烦，集群分布式应用不方便。

　　redis是通过socket访问到缓存服务，效率比Ehcache低，比数据库要快很多，处理集群和分布式缓存方便，有成熟的方案。如果是单个应用或者对缓存访问要求很高的应用，用ehcache。如果是大型系统，存在缓存共享、分布式部署、缓存内容很大的，建议用redis。

　　ehcache也有缓存共享方案，不过是通过RMI或者Jgroup多播方式进行广播缓存通知更新，缓存共享复杂，维护不方便；简单的共享可以，但是涉及到缓存恢复，大数据缓存，则不合适。

```
<dependency>
    <groupId>net.sf.ehcache</groupId>
    <artifactId>ehcache</artifactId>
    <version>2.10.2</version>
</dependency>
```

## Guava Cache

[Guava Cache官方文档 - 简书 (jianshu.com)](https://www.jianshu.com/p/88ec858cc021?from=singlemessage)

Guava  Cache的功能在这些情况下，都是有用的：

> (1).你打算牺牲更多内存来换取速度的提升。
>
> (2).缓存的数据会频繁的使用到
>
> (3).Guava Cache只会把数据存储在内存中(Guava Cache是把数据存储于你运行的单个应用上，它不会吧数据存储在文件或外部的服务器上，如果这满足不了你的需求，你可以考虑使用Memcached)

### population

在你使用Guava Cache时，第一个要问你自己的问题就是： 你有加载或计算一个键所关联的给定值的需求吗？如果有，那么你应该使用CacheLoader。如果没有的话，或许你需要去重写一下默认的实现。但是如果你还是想要原子性"get-if-compute" 语义的话，你可以给get()方法传递一个Callable对象。使用Cache.put()方法可以直接把元素插入到缓存里面，但是我们更偏爱于自动化缓存加载cache loading。因为这让所有的cache缓存的一致性变得更简单。

#### CacheLoader

在创建一个LoadingCache时都会附带着一个CacheLoader,创建一个CacheLoader通常都比较简单，只需要实现  V  load(K  key)  throws  Exception方法就行了。

#### Callable

所有的Guava Cache，不管加载与否 都支持get(K,Callable<V>)方法，这个方法会返回和某个key关联的值或者 从Callable里面计算出来值并把它放入缓存cache中。这个方法提供了一种简单的“ if cached,return ;otherwise create, cache and return ” 模式。

#### 直接插入inserted Directly

可以调用cache.put(key,value)方法向缓存中直接插入值，如果给定键的值已经存在于缓存cache中了，那么原来的值将会被覆盖掉。我们也可以使用Cache.asMap()视图暴露的方法对cache做一些改动。请注意，asMap视图中没有方法可以自动地把条目加载到缓存cache中，因此，Cache.get(K,Callable<V>)，更进一步地说，在这个asMap视图上原子性操作是在自动cache loading的范围之外操作的，所以在cache中加载值，相比于Cache.asMap().putIfAbsent()方法我们更喜欢Cache.get(K,Callable<V>)，因为缓存加载值时，要么使用CacheLoader，要么使用Callable。

### 回收 eviction

最残酷的现实就是我们并没有足够的内存去缓存我们想缓存的一切数据。你必须决定： 在什么时候不应该保存一个缓存条目？

 Guava  提供了三种基本类型的对象回收策略：  基于大小的回收，基于时间的回收，基于引用的回收。

#### 基于大小的回收

如果你的cache缓存不能超过一定大小的话，只需要使用CacheBuilder.maximumSize(long)方法即可。那么缓存cache将会试图回收那些不经常用到的条目。Warning: 缓存会在到达上限之前把某些条目的内存回收掉。

  除此之外，如果不同的条目具有不同权重 --例如，如果你的不同缓存值占用不同的内存空间的话，你可以使用CacheBuilder.weigher(Weigher)方法来指定一个权重，并且可以通过CacheBuilder.maximumWeight(long) 设置最大权重值。在这里补充一个说明，和maximumSize要求的一样，权重值要在条目创建的时候被计算出来的并且在那之后都是不可变的。

#### 基于时间的回收

CacheBuilder为基于时间的回收提供了俩个方法：

>  .expireAfterAccess(long,TimeUnit):    只过期那些持续了指定时间的条目。  注意： 回收条目的顺序和基于大小的回收很相似。
>
>  .expireAfterWrite(long,TimeUnit)： 自条目被创建或最近替换了值之后，过了指定时间后，把这些条目过期。如果缓存中的数据在一段时间之后变的陈旧不可用的话，那么使用这个策略将是十分可取的。

#### 基于引用的回收

### 显示清除

在任何时间，除了等待条目被回收之外，你还可以显示地使用清除数据，可以通过下面的方式来显示地清除：

>    .单独地使用 Cache.invalidate(key)
>
>    .批量清除，可以使用Cache.invalidateAll(keys)
>
>    .清除所有条目，可以使用 Cache.invalidateAll()

### 清除监听器Removal Listener

当一个条目被清除时候，你可以为你的缓存指定一个清除监听器来执行一些操作。可以通过 CacheBuilder.removalListener(RemovalListener)方法添加一个监听器。 RemovalListener会得到一个RemovalNotification，RemovalNotification中会指定清除原因RemovalCause,键和值。

注意：RemovalListener抛出的任何异常都会被日志记录并且吞下去。

### 什么时候执行清理工作

使用CacheBuilder创建的Caches 不会自动执行清理和回收工作 相反，它会在在写操作或者读操作期间，只执行小量的维护maintenance操作。

### 刷新refresh

  刷新和回收不太一样，正如LoadingCache.refresh(K)所说的，刷新一个键key的话，会为这个键加载新的值，这可能是异步的。当键正在被刷新时，会依然把旧值返回给调用者。对比之下，回收会强制要求获取值的操作先等待直到新值被加载进去。

如果在刷新过程中出现了什么异常，那么会依然把旧值保存在cache缓存中，并且会针对这个异常做日志记录同时把异常吞掉。

在刷新时，通过重写CacheLoader.reload(K,V)方法， CacheLoader可以指定一个智能的行为：它允许你在计算新值的过程中，仍然还可以继续使用旧值。

### 特性 Features

####  统计 Statistics

通过使用CacheBuilder.recordStats()，你可以让Guava Cache进行统计信息收集工作，Cache.stats()方法会返回一个缓存状态CacheStats对象，这个缓存状态对象里面提供如下信息：

> ​    (1).hitRate(),返回查询的命中率
>
>    (2).averageLoadPenalty(),加载新值时的平均消耗时间
>
>    (3).evictionCount(),缓存回收的数量。

  还有一些其他的统计信息，这些统计信息在缓存cache调优时，十分有用，如果你这个应用比较重视性能的话，我们建议您关注一下这些统计信息。

#### asMap

用缓存cache的视图，你可以把任一个cache缓存看成一个ConcurrentMap,但是asMap视图是如何跟Cache进行交互的，这里我们需要做一些解释：

>   (1)cache.asMap() 包含当前加载进Cache缓存中的所有条目，例如，cache.asMap().keySet()包含了所有当前已经加载的键。
>
>   (2)asMap().get(key) 本质上等同于cache.getIfPresent(key)并且不会导致值被加载进内存中，这和Map的约定是一致的。
>
>   (3)所有的cache的读操作和写操作都会导致访问时间被重置。

### 中断interruption

加载方法比如get()永远不会抛出一个InterruptedException。

## Memcached

[memcached - a distributed memory object caching system](http://memcached.org/)

[Memcached 教程 | 菜鸟教程 (runoob.com)](https://www.runoob.com/memcached/memcached-tutorial.html)

Memcached是一个自由开源的，高性能，分布式内存对象缓存系统。

Memcached是以LiveJournal旗下Danga Interactive公司的Brad Fitzpatric为首开发的一款软件。现在已成为mixi、hatena、Facebook、Vox、LiveJournal等众多服务中提高Web应用扩展性的重要因素。

Memcached是一种基于内存的key-value存储，用来存储小块的任意数据（字符串、对象）。这些数据可以是数据库调用、API调用或者是页面渲染的结果。

Memcached简洁而强大。它的简洁设计便于快速开发，减轻开发难度，解决了大数据量缓存的很多问题。它的API兼容大部分流行的开发语言。

本质上，它是一个简洁的key-value存储系统。

一般的使用目的是，通过缓存数据库查询结果，减少数据库访问次数，以提高动态Web应用的速度、提高可扩展性。

memcached作为高速运行的分布式缓存服务器，具有以下的特点。

- 协议简单
- 基于libevent的事件处理
- 内置内存存储方式
- memcached不互相通信的分布式

### Memcached 存储命令

```
//Memcached set 命令用于将 value(数据值) 存储在指定的 key(键) 中。
//如果set的key已经存在，该命令可以更新该key所对应的原来的数据，也就是实现更新的作用。
set key flags exptime bytes [noreply] 
value 

//Memcached add 命令用于将 value(数据值) 存储在指定的 key(键) 中。
//如果 add 的 key 已经存在，则不会更新数据(过期的 key 会更新)，之前的值将仍然保持相同，并且您将获得响应 NOT_STORED。
add key flags exptime bytes [noreply]
value

//emcached replace 命令用于替换已存在的 key(键) 的 value(数据值)。
//如果 key 不存在，则替换失败，并且您将获得响应 NOT_STORED。
replace key flags exptime bytes [noreply]
value

//Memcached append 命令用于向已存在 key(键) 的 value(数据值) 后面追加数据 。
append key flags exptime bytes [noreply]
value

//Memcached prepend 命令用于向已存在 key(键) 的 value(数据值) 前面追加数据 。
prepend key flags exptime bytes [noreply]
value

//Memcached CAS（Check-And-Set 或 Compare-And-Swap） 命令用于执行一个"检查并设置"的操作
//它仅在当前客户端最后一次取值后，该key 对应的值没有被其他客户端修改的情况下， 才能够将值写入。
//检查是通过cas_token参数进行的， 这个参数是Memcach指定给已经存在的元素的一个唯一的64位值。
cas key flags exptime bytes unique_cas_token [noreply]
value
```

### Memcached 查找命令

```
//Memcached get 命令获取存储在 key(键) 中的 value(数据值) ，如果 key 不存在，则返回空。
get key

//Memcached gets 命令获取带有 CAS 令牌存 的 value(数据值) ，如果 key 不存在，则返回空。
gets key

//Memcached delete 命令用于删除已存在的 key(键)。
delete key [noreply]

//Memcached incr 与 decr 命令用于对已存在的 key(键) 的数字值进行自增或自减操作。
//incr 与 decr 命令操作的数据必须是十进制的32位无符号整数。
//如果 key 不存在返回 NOT_FOUND，如果键的值不为数字，则返回 CLIENT_ERROR，其他错误返回 ERROR。
incr key increment_value
decr key decrement_value

```

### Memcached 统计命令

```
//Memcached stats 命令用于返回统计信息例如 PID(进程号)、版本号、连接数等。
stats

//Memcached stats items 命令用于显示各个 slab 中 item 的数目和存储时长(最后一次访问距离现在的秒数)。
stats items

//Memcached stats slabs 命令用于显示各个slab的信息，包括chunk的大小、数目、使用情况等。
stats slabs

//Memcached stats sizes 命令用于显示所有item的大小和个数。
//该信息返回两列，第一列是 item 的大小，第二列是 item 的个数。
stats sizes


//Memcached flush_all 命令用于清理缓存中的所有 key=>value(键=>值) 对。
//该命令提供了一个可选参数 time，用于在制定的时间后执行清理缓存操作。
flush_all [time] [noreply]
```

### Memcached 实例

使用 Java 程序连接 Memcached，需要在你的 classpath 中添加 Memcached jar 包。

本站 jar 包下载地址：[spymemcached-2.10.3.jar](https://www.runoob.com/try/download/spymemcached-2.10.3.jar)。

Google Code jar 包下载地址：[spymemcached-2.10.3.jar](http://code.google.com/p/spymemcached/downloads/list)。

以下程序假定 Memcached 服务的主机为 127.0.0.1，端口为 11211。

```
// 本地连接 Memcached 服务
MemcachedClient mcc = new MemcachedClient(new InetSocketAddress("127.0.0.1", 11211));
// 关闭连接
mcc.shutdown();
```

## EVCache

[[由零开始\] EVCache介绍用法和原理_qq497811258的博客-CSDN博客_evcache](https://blog.csdn.net/qq497811258/article/details/108264695)

EVCache是一个开源、快速的分布式缓存
是基于Memcached的内存存储和Spymemcached客户端实现的
是Netflix（网飞）公司开发的
E：Ephemeral：数据存储是短暂的，有自身的存活时间
V：Volatile：数据可以在任何时候消失
Cache：内存级键值对存储

![img](https://img-blog.csdnimg.cn/20200827170736853.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxNDk3ODExMjU4,size_16,color_FFFFFF,t_70#pic_center)

### EVCache应用场景

Netflix用来构建超大容量、高性能、低延时、跨区域的全球可用的缓存数据层
EVCache典型地适合对强一致性没有必须要求的场合
典型用例：Netflix向用户推荐用户感兴趣的电影

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200827170746466.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxNDk3ODExMjU4,size_16,color_FFFFFF,t_70#pic_center)

### 部署

#### 典型部署

EVCache 是线性扩展的，可以在一分钟之内完成扩容，在几分钟之内完成负载均衡和缓存预热。

#### 单节点部署

1、集群启动时，EVCache向服务注册中心（Zookeeper、Eureka）注册各个实例
2、在web应用启动时，通过EVCache的客户端(EVCache Client)查询命名服务中的EVCache服务器列
表，并建立连接。

3、web应用通过EVCache的客户端操作数据，客户端通过key使用一致性hash算法，将数据分片到集
群上。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200827170753483.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxNDk3ODExMjU4,size_16,color_FFFFFF,t_70#pic_center)

#### 多可用区部署

EVCache的跨可用区复制

1.EVCache客户端库包发送SET到缓存系统的本地地区的一个实例服务器中。
2.EVCache客户端库包同时也将写入元数据(包括key，但是不包括要缓存的数据本身)到复制消息队列
(Kafka)
3.本地区的“复制转播”的服务将会从这个消息队列中读取消息。
4.转播服务会从本地缓存中抓取符合key的数据
5.转播会发送一个SET请求到远地区的“复制代理”服务。
6.在远地区，复制代理服务会接受到请求，然后执行一个SET到它的本地缓存，完成复制。
7.在接受地区的本地应用当通过GET操作以后会在本地缓存看到这个已经更新的数据值。

![在这里插入图片描述](https://img-blog.csdnimg.cn/20200827170818290.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxNDk3ODExMjU4,size_16,color_FFFFFF,t_70#pic_center)

## Tair

[Tair - 数据库介绍| 阿里云 (alibabacloud.com)](https://www.alibabacloud.com/help/zh/doc-detail/178311.htm)

[Tair简介_帅性而为1号的博客-CSDN博客_tair](https://blog.csdn.net/zhushuai1221/article/details/52812822)

[深入理解tair - 简书 (jianshu.com)](https://www.jianshu.com/p/ccb17daed766)

Tair是由淘宝网自主开发的Key/Value结构数据存储系统，在淘宝网有着大规模的应用。

Tair于2010年6月30号在[淘宝开源平台](https://link.jianshu.com?t=http%3A%2F%2Fcode.taobao.org%2F)上正式对外开源。

Tair有四种引擎：mdb, rdb, kdb和ldb。分别基于四种开源的key/value数据库：memcached, Redis, Kyoto Cabinet和leveldb。Tair可以让你更方便地使用这些KV数据库。比如Redis没有提供sharding操作，如果有多个Redis Server，你需要自己写代码实现sharding，Tair帮你封装了这些。

### 使用场景

1. 非持久化(mdb,rdb)

数据可以以key/value的形式存储
 数据可以接受丢失
 访问速度要求很高
 单个数据大小不是很大，一般在KB级别
 数据量很大，并且有较大的增长可能性
 数据更新不频繁

1. 持久化(kdb,ldb)

数据可以以key/value的形式存储
 数据需要持久化
 单个数据大小不是很大，一般在KB级别
 数据量很大，并且有较大的增长可能性
 数据的读写比例较高

### 数据的分布问题

分布式系统需要解决的一个重要问题便是决定数据在集群中的分布策略，好的分布策略应该能将数据均衡地分布到所有节点上，并且还应该能适应集群节点的变化。Tair采用的对照表方式较好地满足了这两点。

对照表的行数是一个固定值，这个固定值应该远大于一个集群的物理机器数，由于对照表是需要和每个使用Tair的客户端同步的，所以不能太大，不然同步将带来较大的开销。我们在生产环境中的行数一般为1023 。

### 对照表

下面我们看对照表是怎么完成数据的分布功能的，为了方便，我们这里假设对照表的行数为6。最简单的对照表包含两列，第一列为hash值，第二列为负责该 hash值对应数据的dataserver节点信息。比如我们有两个节点192.168.10.1和192.168.10.2，那么对照表类似：
 0    192.168.10.1
 1    192.168.10.2
 2    192.168.10.1
 3    192.168.10.2
 4    192.168.10.1
 5    192.168.10.2

假设新增了一个节点——192.168.10.3，当configserver发现新增的节点后，会重新构建对照表。构建依据以下两个原则：

1. 数据在新表中均衡地分布到所有节点上。
2. 尽可能地保持现有的对照关系。

Tair支持自定义的备份数，比如你可以设置数据备份为2，以提高数据的可靠性。对照表可以很方便地支持这个特性。我们以行数为6，两个节点为例，2个备份的对照表类似：
 0    192.168.10.1    192.168.10.2
 1    192.168.10.2    192.168.10.1
 2    192.168.10.1    192.168.10.2
 3    192.168.10.2    192.168.10.1
 4    192.168.10.1    192.168.10.2
 5    192.168.10.2    192.168.10.1

第二列为主节点的信息，第三列为辅节点信息。在Tair中，客户端的读写请求都是和主节点交互，所以如果一个节点不做主节点，那么它就退化成单纯的备份节点。因此，多备份的对照表在构建时需要尽可能保证各个节点作为主节点的个数相近。

当有节点不可用时，如果是辅节点，那么configserver会重新为其指定一个辅节点，如果是持久化存储，还将复制数据到新的辅节点上。如果是主节点，那么configserver首先将辅节点提升为主节点，对外提供服务，并指定一个新的辅节点，确保数据的备份数。

对照表在构建时，可以配置将数据的备份分散到不同机架或数据中心的节点上。Tair当前通过设置一个IP掩码来判断机器所属的机架和数据中心信息。

比如你配置备份数为3，集群的节点分布在两个不同的数据中心A和B，则Tair会确保每个机房至少有一份数据。假设A数据中心包含两份数据时，Tair会尽可能将这两份数据分布在不同机架的节点上。这可以减少整个数据中心或某个机架发生故障是数据丢失的风险。

### 轻量级的configserver

从Tair的整体架构图上看，configserver很类似传统分布式集群中的中心节点。整个集群服务都依赖于configserver的正常工作。

但Tair的configserver却是一个轻量级的中心节点，在大部分时候，configserver不可用对集群的服务是不造成影响的。

Tair用户和configserver的交互主要是为了获取数据分布的对照表，当client获取到对照表后，会cache这张表，然后通过查这张表决 定数据存储的节点，所以请求不需要和configserver交互，这使得Tair对外的服务不依赖configserver，所以它不是传统意义上的中 心节点。

configserver维护的对照表有一个版本号，每次新生成表，该版本号都会增加。当有数据节点状态发生变化(比如新增节点或者有节点不可用了)时，configserver会根据当前可用的节点重新生成对照表，并通过数据节点的心跳，将新表同步给数据节点。

当客户端请求数据节点时，数据节点每次都会将自己的对照表的版本号放入response中返回给客户端，客户端接收到response后，会将数据节点返回的版本号和自己的版本号比较，如果不相同，则主动和configserver通信，请求新的对照表。

所以客户端也不需要和configserver保持心跳，以便及时地更新对照表。这使得在正常的情况下，客户端不需要和configserver通信，即使configserver不可用了，也不会对整个集群的服务造成大的影响。

仅有当configserver不可用，此时有客户端需要初始化，那么客户端将取不到对照表信息，这将使得客户端无法正常工作。

### DataServer内部结构

DataServer负责数据的物理存储，并根据configserver构建的对照表完成数据的复制和迁移工作。DataServer具备抽象的存储引擎层，可以很方便地添加新存储引擎。DataServer还有一个插件容器，可以动态地加载/卸载插件。

Tair的存储引擎有一个抽象层，只要满足存储引擎需要的接口，便可以很方便地替换Tair底层的存储引擎。比如你可以很方便地将bdb、tc甚至MySQL作为Tair的存储引擎，而同时使用Tair的分布方式、同步等特性。

Tair默认包含两个存储引擎：mdb和fdb。

mdb是一个高效的缓存存储引擎，它有着和memcached类似的内存管理方式。mdb支持使用share memory，这使得我们在重启Tair数据节点的进程时不会导致数据的丢失，从而使升级对应用来说更平滑，不会导致命中率的较大波动。

fdb是一个简单高效的持久化存储引擎，使用树的方式根据数据key的hash值索引数据，加快查找速度。索引文件和数据文件分离，尽量保持索引文件在内存中，以便减小IO开销。使用空闲空间池管理被删除的空间。

### 自动的复制和迁移

为了增强数据的安全性，Tair支持配置数据的备份数。比如你可以配置备份数为3，则每个数据都会写在不同的3台机器上。得益于抽象的存储引擎层，无论是作为cache的mdb，还是持久化的fdb，都支持可配的备份数。

当数据写入一个节点(通常我们称其为主节点)后，主节点会根据对照表自动将数据写入到其他备份节点，整个过程对用户是透明的。

当有新节点加入或者有节点不可用时，configserver会根据当前可用的节点，重新build一张对照表。数据节点同步到新的对照表时，会自动将在 新表中不由自己负责的数据迁移到新的目标节点。迁移完成后，客户端可以从configserver同步到新的对照表，完成扩容或者容灾过程。整个过程对用户是透明的，服务不中断。

### 插件容器

Tair还内置了一个插件容器，可以支持热插拔插件。

插件由configserver配置，configserver会将插件配置同步给各个数据节点，数据节点会负责加载/卸载相应的插件。

插件分为request和response两类，可以分别在request和response时执行相应的操作，比如在put前检查用户的quota信息等。

插件容器也让Tair在功能方便具有更好的灵活性。

### tair 的负载均衡算法

tair 的分布采用的是一致性哈希算法， 对于所有的key，分到Q个桶中， 桶是负载均衡和数据迁移的基本单位。 config server 根据一定的策略把每个桶指派到不同的data server上。 因为数据按照key做hash算法， 所以可以认为每个桶中的数据基本是平衡的. 保证了桶分布的均衡性， 就保证了数据分布的均衡性。

### 增加或者减少data server

当有某台data server故障不可用的时候， config server会发现这个情况， config server负责重新计算一张新的桶在data server上的分布表， 将原来由故障机器服务的桶的访问重新指派到其它的data server中。这个时候， 可能会发生数据的迁移。比如原来由data server A负责的桶，在新表中需要由 B负责。而B上并没有该桶的数据， 那么就将数据迁移到B上来。同时config server会发现哪些桶的备份数目减少了， 然后根据负载情况在负载较低的data server上增加这些桶的备份。当系统增加data server的时候， config server根据负载，协调data server将他们控制的部分桶迁移到新的data server上。迁移完成后调整路由。当然系统中可能出现减少了某些data server 同时增加另外的一些data server。处理原理同上。 每次路由的变更，config server都会将新的配置信息推给data server。在客户端访问data server的时候， 会发送客户端缓存的路由表的版本号。如果data server发现客户端的版本号过旧，则会通知客户端去config server取一次新的路由表。如果客户端访问某台data server 发生了不可达的情况(该 data server可能宕机了)，客户端会主动去config server取新的路由表。

### 迁移时data server如何对外提供服务

当迁移发生的时候， 我们举个例子， 假设data server A 要把桶 3，4，5 迁移给data server B。因为迁移完成前，客户端的路由表没有变化，客户端对 3， 4， 5 的访问请求都会路由到A。现在假设 3还没迁移， 4 正在迁移中， 5已经迁移完成。那么如果是对3的访问， 则没什么特别， 跟以前一样。如果是对5的访问， 则A会把该请求转发给B，并且将B的返回结果返回给客户，如果是对4的访问，在A处理，同时如果是对4的修改操作会记录修改log。当桶4迁移完成的时候，还要把log发送到B，在B上应用这些log。最终A B上对于桶4来说， 数据完全一致才是真正的迁移完成。当然如果是因为某data server宕机而引发的迁移， 客户端会收到一张中间临时状态的分配表。这张表中，把宕机的data server所负责的桶临时指派给有其备份data server来处理。 这个时候服务是可用的，但是负载可能不均衡。当迁移完成之后，才能重新达到一个新的负载均衡的状态。

### 桶在data server上分布时的策略

程序提供了两种生成分配表的策略， 一种叫做负载均衡优先， 一种叫做位置安全优先: 我们先看负载优先策略。当采用负载优先策略的时候，config server会尽量的把桶均匀的分布到各个data server上。 所谓尽量是指在不违背下面的原则的条件下尽量负载均衡。

1、每个桶必须有COPY_COUNT份数据

2、一个桶的各份数据不能在同一台主机上

位置安全优先原则是说， 在不违背上面两个原则的条件下， 还要满足位置安全条件，然后再考虑负载均衡。 位置信息的获取是通过 _pos_mask(参见安装部署文档中关于配置项的解释) 计算得到。一般我们通过控制 _pos_mask 来使得不同的机房具有不同的位置信息。 那么在位置安全优先的时候，必须被满足的条件要增加一条， 一个桶的各份数据不能都位于相同的一个位置(不在同一个机房)。这里有一个问题， 假如只有两个机房， 机房1中有100台data server， 机房2中只有1台data server。这个时候， 机房2中data server的压力必然会非常大。于是这里产生了一个控制参数 _build_diff_ratio(参见安装部署文档)。 当机房差异比率大于这个配置值时， config server也不再build新表。 机房差异比率是如何计出来的呢? 首先找到机器最多的机房，不妨设使RA， data server数量是SA。 那么其余的data server的数量记做SB。则机房差异比率=|SA – SB|/SA。 因为一般我们线上系统配置的COPY_COUNT是3。 在这个情况下， 不妨设只有两个机房RA和RB， 那么两个机房什么样的data server数量是均衡的范围呢? 当差异比率小于 0。5的时候是可以做到各台data server负载都完全均衡的。这里有一点要注意：假设RA机房有机器6台，RB有机器3台。那么差异比率 = 6 – 3 / 6 = 0.5。这个时候如果进行扩容，在机房A增加一台data server，扩容后的差异比率 = 7 – 3 / 7 = 0.57。也就是说，只在机器数多的机房增加data server会扩大差异比率。 如果我们的_build_diff_ratio配置值是0.5。那么进行这种扩容后， config server会拒绝再继续build新表。

### tair 的一致性和可靠性问题

分布式系统中的可靠性和一致性是无法同时保证的，因为我们必须允许网络错误的发生。tair 采用复制技术来提高可靠性，并且为了提高效率做了一些优化，事实上在没有错误发生的时候，tair 提供的是一种强一致性。但是在有data server发生故障的时候，客户有可能在一定时间窗口内读不到最新的数据。 甚至发生最新数据丢失的情况。

## Twemproxy

[Twemproxy 缓存代理服务器_放错位的天才的博客-CSDN博客](https://blog.csdn.net/weixin_30825199/article/details/94856427)

[Twemproxy](https://github.com/twitter/twemproxy)（又称为nutcracker）是一个轻量级的Redis和Memcached代理，主要用来减少对后端缓存服务器的连接数。Twemproxy是由Twitter开源出来的缓存服务器集群管理工具，主要用来弥补Redis/Memcached 对集群（cluster）管理的不足。

antirez（Redis作者）写过一篇对[twemproxy的介绍](http://antirez.com/news/44)，他认为twemproxy是目前Redis 分片管理的最好方案，虽然antirez的[Redis cluster](http://redis.io/topics/cluster-spec)正在实现并且对其给予厚望，但从现有的cluster实现上还是认为cluster除了增加Redis复杂度，对于集群的管理没有twemproxy来的轻量和有效。

谈到集群管理不得不又说到数据的分片管理（shard），为了满足数据的日益增长和扩展性，数据存储系统一般都需要进行一定的分片，如传统的MySQL进行横向分表和纵向分表，然后应用程序访问正确的位置就需要找的正确的表。这时候，这个数据定向工作一般有三个位置可以放：

- 数据存储系统本身支持，Redis Cluster就是典型的试图在数据存储系统上支持分片；
- 客户端支持，Memcached的客户端对分片的支持就是客户端层面的；
- 代理支持，twemproxy就是试图在服务器端和客户端中间建代理支持；

## Aerospike

[Aerospike - Next Generation, NoSQL Data Platform](https://www.aerospike.com/)

[Aerospike使用介绍_dazheng-CSDN博客_aerospike](https://blog.csdn.net/dazheng/article/details/47156653)

Aerospike(以下简称AS）是一个以分布式为核心基础，可基于行随机存取内存中索引、数据或SSD存储中数据的数据库。它主要用于百G、数T等大数据量并且在数万以上高并发情况下，对性能也有ms读取插入要求的场景。目前主要集中于互联网广告行业，如eXelate、BlueKai、MediaV、 InMobi、 applovin等。

### 特性

- 可预见的高性能

  99% 的响应可在 1 毫秒内实现，99.9% 的响应可在 5 毫秒内实现。

- 混合架构

  索引存储在 RAM 中，而数据存储在闪存/固态硬盘 (SSD) 上。

- 群集感知客户端软件

  客户端知晓数据的存放位置，因此通常能够通过一次单跳检索到数据

- 无热点

  使用复杂的哈希函数来确保数据均等地分布到所有可用节点，从而将需求平均分布到各资源上。

- 数据完整性

  保持了高度的一致性，或者允许对跨越多个群集和数据中心的一致性进行调节。

- 线性扩展

  能够根据需要安装到多个数据中心内分组为多个群集的多个节点上。添加节点，无需分片，无需人工干预

- 跨数据中心支持

  不同数据中心内的群集能够自动协调，从而实现绝对的可靠性

- 提供API的语言

  AS支持多种语言，诸如C/C++、 Java、 C#、 Python、 PHP、 Go、 Node.js、 Ruby、 Erlang、 libevent2 (C)、 Perl等等。

### 基本概念

- namespace

  策略容器，类似RDBMS中的schema，可以设置副本数、内存大小、有效时长、存储引擎、文件存储位置

- Sets

  类似RDBMS中的表

- Records

  类似RDBMS中的行，行级的失效时间（TTL）

- Bin

  类似RDBMS中的列，一行可以有多个bins

![这里写图片描述](https://img-blog.csdn.net/20150730205058926)

### AS和Redis的区别

- AS优势
  - 数据可存储于内存、SSD
  - 同步复制，无需手工配置，可做机架感知、跨数据中心复制，不会丢失数据
  - 机群自动扩展，自动平衡数据
  - 客户端感知集群，app不需要知道集群节点
  - 二级索引、汇总
  - 概念、处理方式与RDBMS接近
- Redis优势
  - 多种数据结构
  - 完善的文档，广泛的使用
  - 丰富的客户端
  - 结构简单