# 分布式消息服务中间件

消息队列作为高并发系统的核心组件之一，能够帮助业务系统解构提升开发效率和系统稳定性。主要具有以下优势：

- 削峰填谷（主要解决瞬时写压力大于应用服务能力导致消息丢失、系统奔溃等问题）
- 系统解耦（解决不同重要程度、不同能力级别系统之间依赖导致一死全死）
- 提升性能（当存在一对多调用时，可以发一条消息给消息系统，让消息系统通知相关系统）
- 蓄流压测（线上有些链路不好压测，可以通过堆积一定量消息再放开来压测）

## RabbitMQ

[Messaging that just works — RabbitMQ](https://www.rabbitmq.com/)

[RabbitMQ - 简书 (jianshu.com)](https://www.jianshu.com/p/78847c203b76)

消息总线(Message Queue)，是一种跨进程、异步的通信机制，用于上下游传递消息。由消息系统来确保消息的可靠传递。

用来应用解耦、异步、流量削锋、数据分发、错峰流控、日志收集等等.。

衡量标准：服务性能、数据存储、集群架构

RabbitMQ是一个开源的消息代理和队列服务器，用来通过普通协议在不同的应用之间共享数据(跨平台跨语言)。RabbitMQ是使用Erlang语言编写，并且基于AMQP协议实现。

※**`AMQP(Advanced Message Queuing Protocol)`**高级消息队列协议：高级消息队列协议。它是应用层协议的一个开放标准，为面向消息的中间件设计，基于此协议的客户端与消息中间件可传递消息，并不受产品、开发语言等条件的限制。

AMQP中消息的路由过程和JMS存在一些差别。AMQP中增加了Exchange和Binging的角色。生产者把消息发布到Exchange上，消息最终到达队列并被消费者接收，而Binding决定交换器的消息应该发送到哪个队列。

### RabbitMQ的优势

**`可靠性(Reliablity)：`**使用了一些机制来保证可靠性，比如持久化、传输确认、发布确认。

**`灵活的路由(Flexible Routing)：`**在消息进入队列之前，通过Exchange来路由消息。对于典型的路由功能，Rabbit已经提供了一些内置的Exchange来实现。针对更复杂的路由功能，可以将多个Exchange绑定在一起，也通过插件机制实现自己的Exchange。

**`消息集群(Clustering)：`**多个RabbitMQ服务器可以组成一个集群，形成一个逻辑Broker。

**`高可用(Highly Avaliable Queues)：`**队列可以在集群中的机器上进行镜像，使得在部分节点出问题的情况下队列仍然可用。

**`多种协议(Multi-protocol)：`**支持多种消息队列协议，如STOMP、MQTT等。

**`多种语言客户端(Many Clients)：`**几乎支持所有常用语言，比如Java、.NET、Ruby等。

**`管理界面(Management UI)：`**提供了易用的用户界面，使得用户可以监控和管理消息Broker的许多方面。

**`跟踪机制(Tracing)：`**如果消息异常，RabbitMQ提供了消息的跟踪机制，使用者可以找出发生了什么。

**`插件机制(Plugin System)：`**提供了许多插件，来从多方面进行扩展，也可以编辑自己的插件。

### RabbitMQ的整体架构

![img](https://upload-images.jianshu.io/upload_images/17039633-b0adf1dfade2f122.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

### RabbitMQ的消息流转

![img](https://upload-images.jianshu.io/upload_images/17039633-6fe89a2074201de7.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

### RabbitMQ各组件功能

**`Broker：`**标识消息队列服务器实体.

**`Virtual Host：`**虚拟主机。标识一批交换机、消息队列和相关对象。虚拟主机是共享相同的身份认证和加密环境的独立服务器域。每个vhost本质上就是一个mini版的RabbitMQ服务器，拥有自己的队列、交换器、绑定和权限机制。vhost是AMQP概念的基础，必须在链接时指定，RabbitMQ默认的vhost是 /。

**`Exchange：`**交换器，用来接收生产者发送的消息并将这些消息路由给服务器中的队列。

**`Queue：`**消息队列，用来保存消息直到发送给消费者。它是消息的容器，也是消息的终点。一个消息可投入一个或多个队列。消息一直在队列里面，等待消费者连接到这个队列将其取走。

**`Banding：`**绑定，用于消息队列和交换机之间的关联。一个绑定就是基于路由键将交换机和消息队列连接起来的路由规则，所以可以将交换器理解成一个由绑定构成的路由表。

**`Channel：`**信道，多路复用连接中的一条独立的双向数据流通道。信道是建立在真实的TCP连接内地虚拟链接，AMQP命令都是通过信道发出去的，不管是发布消息、订阅队列还是接收消息，这些动作都是通过信道完成。因为对于操作系统来说，建立和销毁TCP都是非常昂贵的开销，所以引入了信道的概念，以复用一条TCP连接。

**`Connection：`**网络连接，比如一个TCP连接。

**`Publisher：`**消息的生产者，也是一个向交换器发布消息的客户端应用程序。

**`Consumer：`**消息的消费者，表示一个从一个消息队列中取得消息的客户端应用程序。

**`Message：`**消息，消息是不具名的，它是由消息头和消息体组成。消息体是不透明的，而消息头则是由一系列的可选属性组成，这些属性包括routing-key(路由键)、priority(优先级)、delivery-mode(消息可能需要持久性存储[消息的路由模式])等。

![img](https://upload-images.jianshu.io/upload_images/5015984-367dd717d89ae5db.png?imageMogr2/auto-orient/strip|imageView2/2/format/webp)

### RabbitMQ的多种Exchange类型

Exchange分发消息时，根据类型的不同分发策略有区别。目前共四种类型：direct、fanout、topic、headers(headers匹配AMQP消息的header而不是路由键(Routing-key)，此外headers交换器和direct交换器完全一致，但是性能差了很多，目前几乎用不到了。)

### TTL

TTL(Time To Live)：生存时间。RabbitMQ支持消息的过期时间，一共两种。

- 在消息发送时可以进行指定。通过配置消息体的properties，可以指定当前消息的过期时间。
- 在创建Exchange时可进行指定。从进入消息队列开始计算，只要超过了队列的超时时间配置，那么消息会自动清除。

### 死信队列DLX

**`死信队列(DLX Dead-Letter-Exchange)：`**利用DLX，当消息在一个队列中变成死信(dead message)之后，它能被重新publish到另一个Exchange，这个Exchange就是DLX。

DLX也是一个正常的Exchange，和一般的Exchange没有区别，它能在任何的队列上被指定，实际上就是设置某个队列的属性。

当这个队列中有死信时，RabbitMQ就会自动的将这个消息重新发布到设置的Exchange上去，进而被路由到另一个队列。

可以监听这个队列中消息做相应的处理，这个特性可以弥补RabbitMQ3.0之前支持的immediate参数的功能。

消息变成死信的几种情况：

- 消息被拒绝(basic.reject/basic.nack)并且requeue=false
- 消息TTL过期
- 队列达到最大长度

死信队列设置：需要设置死信队列的exchange和queue，然后通过routing key进行绑定。只不过我们需要在队列加上一个参数即可。

只需要通过监听该死信队列即可处理死信消息。还可以通过死信队列完成延时队列。

```jsx
Map<String, Object> arguments = Maps.newHashMapWithExpectedSize(3);
arguments.put("x-message-ttl", dlx-ttl);
arguments.put("x-dead-letter-exchange","exchange-name");
arguments.put("x-dead-letter-routing-key", "routing-key");
Queue ret = QueueBuilder.durable("queue-name".withArguments(arguments).build();
```

### 消费端ACK与NACK

消费端进行消费的时候，如果由于业务异常可以进行日志的记录，然后进行补偿。由于服务器宕机等严重问题，我们需要手动进行ACK保障消费端消费成功。

消费端重回队列是为了对没有成功处理消息，把消息重新返回到Broker。一般来说，实际应用中都会关闭重回队列，也就是设置为false。

※ACK (Acknowledge character）即是确认字符，在数据通信中，接收站发给发送站的一种传输类[控制字符](https://baike.baidu.com/item/控制字符/6913704)。表示发来的数据已确认接收无误。

```java
// deliveryTag：消息在mq中的唯一标识
// multiple：是否批量(和qos设置类似的参数)
// requeue：是否需要重回队列。或者丢弃或者重回队首再次消费。
public void basicNack(long deliveryTag, boolean multiple, boolean requeue) 
```

### 生产者Confirm机制

- 消息的确认，是指生产者投递消息后，如果Broker收到消息，则会给我们生产者一个应答。
- 生产者进行接受应答，用来确认这条消息是否正常的发送到了Broker，这种方式也是消息的可靠性投递的核心保障！

Confirm确认消息

1、在channel上开启确认模式：channel.confirmSelect()
 2、在channel上开启监听：addConfirmListener，监听成功和失败的处理结果，根据具体的结果对消息进行重新发送或记录日志处理等后续操作。

![img](https://upload-images.jianshu.io/upload_images/17039633-95cb101479ed6092.png?imageMogr2/auto-orient/strip|imageView2/2/w/958/format/webp)

### Return消息机制

Return Listener用于处理一些不可路由的消息。

我们的消息生产者，通过指定一个Exchange和Routing，把消息送达到某一个队列中去，然后我们的消费者监听队列进行消息的消费处理操作。

但是在某些情况下，如果我们在发送消息的时候，当前的exchange不存在或者指定的路由key路由不到，这个时候我们需要监听这种不可达消息，就需要使用到Returrn Listener。

基础API中有个关键的配置项`Mandatory`：如果为true，监听器会收到路由不可达的消息，然后进行处理。如果为false，broker端会自动删除该消息。

通过chennel.addReturnListener(ReturnListener rl)传入已经重写过handleReturn方法的ReturnListener。

### 消费端自定义监听(推模式和拉模式pull/push)

一般通过while循环进行consumer.nextDelivery()方法进行获取下一条消息进行那个消费。(通过while将拉模式模拟成推模式，但是死循环会耗费CPU资源。)

通过自定义Consumer，实现更加方便、可读性更强、解耦性更强的方式。(现默认使用的模式，直接订阅到queue上，如果有数据，就等待mq推送过来)

```css
Basic.Consume将信道(Channel)置为接收模式，直到取消队列的订阅为止。
在接受模式期间，RabbitMQ会不断的推送消息给消费者。
当然推送消息的个数还是受Basic.Qos的限制。
如果只想从队列获得单条消息而不是持续订阅，建议还是使用Basic.Get进行消费。
但是不能将Basic.Get放在一个循环里来代替Basic.Consume，这样会严重影响RabbitMQ的性能。
如果要实现高吞吐量，消费者理应使用Basic.Consume方法。
```

![img](https://upload-images.jianshu.io/upload_images/17039633-4f6e055501e90ae5.png?imageMogr2/auto-orient/strip|imageView2/2/w/1005/format/webp)

### 如何保证幂等性

消费端实现幂等性，就意味着我们的消息永远不会消费多次，即使我们收到了多条一样的信息。

- 唯一ID+指纹码机制，利用数据库主键去重

```csharp
select count(1) from table where id = id+指纹码
优点：实现简单
缺点：高并发下有数据库写入的性能瓶颈
解决：跟进ID进行分库分表进行算法路由
```

- 利用redis的原子性去实现

```undefined
问题1：是否需要落库。如果落库，如何保证数据的一致性和原子性？
问题2：如果不进行落库，缓存种的数据如果设置定时同步的策略？
```

### 如何保证可靠性

什么是生产端的可靠性投递？

- 保证消息的成功发出
- 保障MQ节点的成功接受
- 发送端收到MQ节点(Broker)确认应答
- 完善消息的补偿机制

解决方案

- 消息落库，对消息状态进行变更。

![img](https://upload-images.jianshu.io/upload_images/17039633-7359ebe49f3da8be.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

```undefined
缺点：对数据库有多次操作。不适用于高并发业务。
```

- 消息的延迟投递，做二次确认，回调检查。

![img](https://upload-images.jianshu.io/upload_images/17039633-cca034c274ab484c.png?imageMogr2/auto-orient/strip|imageView2/2/w/1200/format/webp)

```css
拆出一个回调服务。将落库、检查等操作安排至回调服务上。
1：发送者发送信息至MQ，消费者为下游业务方。
      1.1：成功后，作为发送者发送信息至MQ，消费者为回调服务。
              1.1.1 回调服务接受数据后，落库。
       1.2：失败，等待发送者的延时投递信息。
2、发送者发送延迟投递信息至MQ，消费者为回调服务。
      1.1：查库，确认下游服务方消费已成功。
      1.2：查库，确认下游服务方消费失败，通过rpc调用发送者的接口重新发送。

消息发送者发送的两条信息是同时发送的。

减少了对库的操作，同时解耦，保证了性能，不能百分百保证可靠性
```

### 消费端如何限流

当海量消息瞬间推送过来，单个客户端无法同时处理那么多数据，严重会导致系统宕机。这时，需要削峰。

RabbitMQ提供了一种qos(服务质量保证)功能。即在非自动确认消息的前提下(非ACK)，如果一定数目的消息(通过基于consume或者channel设置qos的值)未被确认前，不进行消费新的消息。

```csharp
// prefetchSize：消息体大小限制；0为不限制
// prefetchCount：RabbitMQ同时给一个消费者推送的消息个数。即一旦有N个消息还没有ack，则该consumer将block掉，直到有消息ack。默认是1.
// global：限流策略的应用级别。consumer[false]、channel[true]。
void BasicQos(unit prefetchSize, unshort prefetchCount, bool global);
channel.basicQos(...);
```

### Channel模式和Connection模式

**`CHANNEL模式：`**程序运行期间ConnectionFactory会维护着一个Connection，所有的操作都会使用这个Connection，但一个Connection中可以有多个Channel，操作rabbitmq之前都必须先获取到一个Channel，否则就会阻塞（可以通过setChannelCheckoutTimeout()设置等待时间），这些Channel会被缓存（缓存的数量可以通过setChannelCacheSize()设置）；

**`CONNECTION模式：`**这个模式下允许创建多个Connection，会缓存一定数量的Connection，每个Connection中同样会缓存一些Channel，除了可以有多个Connection，其它都跟CHANNEL模式一样。

### 消费端的Concurrency和Prefetch模式

在通常的使用中(Java项目)，我们一般会结合spring-amqp框架来使用RabbitMQ，spring-amqp底层调用RabbitMQ的java client来和Broker交互，比如我们会用如下配置来建立RabbitMQ的连接池、声明Queue以及指明监听者的监听行为：



```java
<rabbit:connection-factory id="connectionFactory" />

<!-- template非必须，主要用于生产者发送消息-->
<rabbit:template id="template" connection-factory="connectionFactory" />

<rabbit:queue name="remoting.queue" />
<rabbit:listener-container connection-factory="connectionFactory" concurrency="2" prefetch="3">
    <rabbit:listener ref="listener" queue-names="remoting.queue" />
</rabbit:listener-container>
```

listener-container可以设置消费者在监听Queue的时候的各种参数，其中concurrency和prefetch是比较重要的参数。

concurrency设置的是对每个listener在初始化的时候设置的并发消费者的个数，prefetch是每次从一次性从broker里面取的待消费的消息的个数。

### RabbitMQ集群

RabbitMQ最优秀的功能之一就是内建集群，这个功能涉及的目的是允许消费者和生产者在节点崩溃的情况下继续运行，以及通过添加更多的节点来线性扩展消息通信吞吐量。RabbitMQ内部利用Erlang提供的分布式通信框架OTP来满足上述需求，使客户端在失去一个RabbitMQ节点连接的情况下，还是能够重新连接到集群中的其他节点继续胜场、消费信息。

RabbitMQ会始终记录以下四中类型的内部元数据：

- 队列元数据：包括队列名称和他们的属性，比如是否可持久化，是否可持久化，是否自动删除。
- 交换器元数据：交换器名称、类型、属性。
- 绑定元数据：内部是一张表格，记录如何将消息路由到队列。
- vhost元数据：为vhost内部的队列、交换器、绑定提供命名空间和安全属性。

在单一节点中，RabbitMQ会将所有这些信息存储在内存中，同时将标记为可持久化的队列、交换器、 绑定存储在硬盘上。存到硬盘上可以确保队列和交换器在节点重启后能够重建。而在集群模式下，同样也提供了两种选择：存到硬盘上(独立节点的默认配置)，存在内存中。

如果在集群中创建队列，集群只会在单个节点而不是所有节点上创建完整的队列信息（元数据、状态、内容）。结果是只有队列的所有者节点知道有关队列的所有信息，因此当集群节点崩溃时，该节点的队列和绑定就消失了，并且任何匹配该队列的绑定的新消息也丢失了。还好RabbitMQ 2.6.0之后提供了镜像队列以避免集群节点故障导致的队列内容不可用。

RabbitMQ 集群中可以共享 user、vhost、exchange等，所有的数据和状态都是必须在所有节点上复制的，例外就是上面所说的消息队列。RabbitMQ 节点可以动态的加入到集群中。

当在集群中声明队列、交换器、绑定的时候，这些操作会直到所有集群节点都成功提交元数据变更后才返回。集群中有内存节点和磁盘节点两种类型，内存节点虽然不写入磁盘，但是它的执行比磁盘节点要好。内存节点可以提供出色的性能，磁盘节点能保障配置信息在节点重启后仍然可用，那集群中如何平衡这两者呢？

RabbitMQ 只要求集群中至少有一个磁盘节点，所有其他节点可以是内存节点，当节点加入或离开集群时，它们必须要将该变更通知到至少一个磁盘节点。如果只有一个磁盘节点，刚好又是该节点崩溃了，那么集群可以继续路由消息，但不能创建队列、创建交换器、创建绑定、添加用户、更改权限、添加或删除集群节点。换句话说集群中的唯一磁盘节点崩溃的话，集群仍然可以运行，但直到该节点恢复，否则无法更改任何东西。

## RocketMQ

[Apache RocketMQ](http://rocketmq.apache.org/)

[RocketMQ吐血总结_Java、Go 双核战略-CSDN博客_rocketmq](https://blog.csdn.net/javahongxi/article/details/84931747)

[Rocketmq原理&最佳实践 - 简书 (jianshu.com)](https://www.jianshu.com/p/2838890f3284)

[RocketMQ架构模块解析_Java、Go 双核战略-CSDN博客_rocketmq架构](https://blog.csdn.net/javahongxi/article/details/72956608)

[RocketMQ高并发读写_Java、Go 双核战略-CSDN博客_rocketmq 读写队列](https://blog.csdn.net/javahongxi/article/details/72956619)

[Rocketmq 深入研究Topic - 程序员大本营 (pianshen.com)](https://www.pianshen.com/article/1829201002/)

### 介绍

- RocketMQ是一款分布式消息中间件，最初是由阿里巴巴消息中间件团队研发并大规模应用于生产系统，满足线上海量消息堆积的需求， 在2016年底捐赠给Apache开源基金会成为孵化项目，经过不到一年时间正式成为了Apache顶级项目；早期阿里曾经基于ActiveMQ研发消息系统， 随着业务消息的规模增大，瓶颈逐渐显现，后来也考虑过Kafka，但因为在低延迟和高可靠性方面没有选择，最后才自主研发了RocketMQ， 各方面的性能都比目前已有的消息队列要好，RocketMQ和Kafka在概念和原理上都非常相似，所以也经常被拿来对比；RocketMQ默认采用长轮询的拉模式， 单机支持千万级别的消息堆积，可以非常好的应用在海量消息系统中。

### 优势

支持事务型消息（消息发送和DB操作保持两方的最终一致性，rabbitmq和kafka不支持）
 •       支持结合rocketmq的多个系统之间数据最终一致性（多方事务，二方事务是前提）
 •       支持18个级别的延迟消息（rabbitmq和kafka不支持）
 •       支持指定次数和时间间隔的失败消息重发（kafka不支持，rabbitmq需要手动确认）
 •       支持consumer端tag过滤，减少不必要的网络传输（rabbitmq和kafka不支持）
 •       支持重复消费（rabbitmq不支持，kafka支持）

### 架构

![img](https://img-blog.csdnimg.cn/20181210122757229.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFob25neGk=,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/20181210123535453.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFob25neGk=,size_16,color_FFFFFF,t_70)

![img](https://img-blog.csdnimg.cn/20181210123438946.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFob25neGk=,size_16,color_FFFFFF,t_70)

### 概念模型

#### 基本的概念模型

![img](https://img-blog.csdnimg.cn/20181210123019699.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFob25neGk=,size_16,color_FFFFFF,t_70)

#### 扩展后段概念模型

![img](https://img-blog.csdnimg.cn/20181210123113472.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFob25neGk=,size_16,color_FFFFFF,t_70)

#### 存储模型

![img](https://img-blog.csdnimg.cn/20181210123222677.jpeg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L2phdmFob25neGk=,size_16,color_FFFFFF,t_70)

### 架构模块

RocketMQ集群中包含4个模块：Namesrv, Broker, Producer, Consumer。



- **Namesrv**: 存储当前集群所有Brokers信息、Topic跟Broker的对应关系。

- **Broker**: 集群最核心模块，主要负责Topic消息存储、消费者的消费位点管理（消费进度）。

- **Producer**: 消息生产者，每个生产者都有一个ID(编号)，多个生产者实例可以共用同一个ID。同一个ID下所有实例组成一个生产者集群。

- **Consumer**: 消息消费者，每个订阅者也有一个ID(编号)，多个消费者实例可以共用同一个ID。同一个ID下所有实例组成一个消费者集群。

  1，启动Namesrv，Namesrv起来后监听端口，等待Broker、Produer、Consumer连上来，相当于一个路由控制中心。
  2，Broker启动，跟所有的Namesrv保持长连接，定时发送心跳包。心跳包中包含当前Broker信息(IP+端口等)以及存储所有topic信息。注册成功后，namesrv集群中就有Topic跟Broker的映射关系。
  3，收发消息前，先创建topic，创建topic时需要指定该topic要存储在哪些Broker上。也可以在发送消息时自动创建Topic。
  4，Producer发送消息，启动时先跟Namesrv集群中的其中一台建立长连接，并从Namesrv中获取当前发送的Topic存在哪些Broker上，然后跟对应的Broker建立长连接，直接向Broker发消息。
  5，Consumer跟Producer类似。跟其中一台Namesrv建立长连接，获取当前订阅Topic存在哪些Broker上，然后直接跟Broker建立连接通道，开始消费消息。

#### Names

1. Namesrv用于存储Topic、Broker关系信息，功能简单，稳定性高。多个Namesrv之间相互没有通信，单台Namesrv宕机不影响其他Namesrv与集群；即使整个Namesrv集群宕机，已经正常工作的Producer，Consumer，Broker仍然能正常工作，但新起的Producer, Consumer，Broker就无法工作。

2. Namesrv压力不会太大，平时主要开销是在维持心跳和提供Topic-Broker的关系数据。但有一点需要注意，Broker向Namesr发心跳时，会带上当前自己所负责的所有Topic信息，如果**Topic个数太多（万级别）**，会导致一次心跳中，就Topic的数据就几十M，网络情况差的话，网络传输失败，心跳失败，导致Namesrv误认为Broker心跳失败。

3. 客户端自动创建，Math.min算法决定最多只会创建8个(BrokerConfig)队列，若要超过8个，可通过控制台创建/修改，Topic配置保存在store/config/topics.json

4. 消费负载均衡的最小粒度是队列，Consumer的数量应不大于队列数

5. 读写队列数(writeQueueNums/readQueueNums)是RocketMQ特有的概念，可通过console修改。当readQueueNums不等于writeQueueNums时，会有什么影响呢？

   ```html
   topicRouteData = this.mQClientAPIImpl.getDefaultTopicRouteInfoFromNameServer(defaultMQProducer.getCreateTopicKey(), 1000 * 3);
       if (topicRouteData != null) {
           for (QueueData data : topicRouteData.getQueueDatas()) {
               int queueNums = Math.min(defaultMQProducer.getDefaultTopicQueueNums(), data.getReadQueueNums());
               data.setReadQueueNums(queueNums);
               data.setWriteQueueNums(queueNums);
           }
       }
   ```

- 心跳机制
  - 单个Broker跟所有Namesrv保持心跳请求，心跳间隔为30秒，心跳请求中包括当前Broker所有的Topic信息。Namesrv会反查Broer的心跳信息， 如果某个Broker在2分钟之内都没有心跳，则认为该Broker下线，调整Topic跟Broker的对应关系。但此时Namesrv不会主动通知Producer、Consumer有Broker宕机。
  - Consumer跟Broker是长连接，会每隔30秒发心跳信息到Broker。Broker端每10秒检查一次当前存活的Consumer，若发现某个Consumer 2分钟内没有心跳， 就断开与该Consumer的连接，并且向该消费组的其他实例发送通知，触发该消费者集群的负载均衡(rebalance)。
  - 生产者每30秒从Namesrv获取Topic跟Broker的映射关系，更新到本地内存中。再跟Topic涉及的所有Broker建立长连接，每隔30秒发一次心跳。 在Broker端也会每10秒扫描一次当前注册的Producer，如果发现某个Producer超过2分钟都没有发心跳，则断开连接。

#### Broker

1，**高并发读写服务**

Broker的高并发读写主要是依靠以下两点：

- **消息顺序写**，所有Topic数据同时只会写一个文件，一个文件满1G，再写新文件，真正的顺序写盘，使得发消息TPS大幅提高。
- **消息随机读**，RocketMQ尽可能让读命中系统pagecache，因为操作系统访问pagecache时，即使只访问1K的消息，系统也会提前预读出更多的数据，在下次读时就可能命中pagecache，减少IO操作。

**2，负载均衡与动态伸缩**

**负载均衡**：Broker上存Topic信息，Topic由多个队列组成，队列会平均分散在多个Broker上，而Producer的发送机制保证消息尽量平均分布到所有队列中，最终效果就是所有消息都平均落在每个Broker上。

**动态伸缩能力（非顺序消息）**：Broker的伸缩性体现在两个维度：Topic, Broker。

- Topic维度：假如一个Topic的消息量特别大，但集群水位压力还是很低，就可以扩大该Topic的队列数，Topic的队列数跟发送、消费速度成正比。
- Broker维度：如果集群水位很高了，需要扩容，直接加机器部署Broker就可以。Broker起来后向Namesrv注册，Producer、Consumer通过Namesrv发现新Broker，立即跟该Broker直连，收发消息。

**3，高可用&高可靠**

高可用：集群部署时一般都为主备，备机实时从主机同步消息，如果其中一个主机宕机，备机提供消费服务，但不提供写服务。

高可靠：所有发往broker的消息，有同步刷盘和异步刷盘机制；同步刷盘时，消息写入物理文件才会返回成功，异步刷盘时，只有机器宕机，才会产生消息丢失，broker挂掉可能会发生，但是机器宕机崩溃是很少发生的，除非突然断电。

#### 消费者

消费者启动时需要指定Namesrv地址，与其中一个Namesrv建立长连接。消费者每隔30秒从nameserver获取所有topic的最新队列情况，这意味着某个broker如果宕机，客户端最多要30秒才能感知。连接建立后，从namesrv中获取当前消费Topic所涉及的Broker，直连Broker。

Consumer跟Broker是长连接，会每隔30秒发心跳信息到Broker。Broker端每10秒检查一次当前存活的Consumer，若发现某个Consumer 2分钟内没有心跳，就断开与该Consumer的连接，并且向该消费组的其他实例发送通知，触发该消费者集群的负载均衡。

**消费者端的负载均衡**
先讨论消费者的消费模式，消费者有两种模式消费：集群消费，广播消费。

- 广播消费：每个消费者消费Topic下的所有队列。
- 集群消费：一个topic可以由同一个ID下所有消费者分担消费。具体例子：假如TopicA有6个队列，某个消费者ID起了2个消费者实例，那么每个消费者负责消费3个队列。如果再增加一个消费者ID相同消费者实例，即当前共有3个消费者同时消费6个队列，那每个消费者负责2个队列的消费。

消费者端的负载均衡，就是集群消费模式下，同一个ID的所有消费者实例平均消费该Topic的所有队列。

#### 生产者

roducer启动时，也需要指定Namesrv的地址，从Namesrv集群中选一台建立长连接。如果该Namesrv宕机，会自动连其他Namesrv。直到有可用的Namesrv为止。

生产者每30秒从Namesrv获取Topic跟Broker的映射关系，更新到本地内存中。再跟Topic涉及的所有Broker建立长连接，每隔30秒发一次心跳。在Broker端也会每10秒扫描一次当前注册的Producer，如果发现某个Producer超过2分钟都没有发心跳，则断开连接。

**生产者端的负载均衡**

生产者发送时，会自动轮询当前所有可发送的broker，一条消息发送成功，下次换另外一个broker发送，以达到消息平均落到所有的broker上。

这里需要注意一点：假如某个Broker宕机，意味生产者最长需要30秒才能感知到。在这期间会向宕机的Broker发送消息。当一条消息发送到某个Broker失败后，会往该broker自动再重发2次，假如还是发送失败，则抛出发送失败异常。业务捕获异常，重新发送即可。客户端里会自动轮询另外一个Broker重新发送，这个对于用户是透明的。

### 图例

![img](https://www.pianshen.com/images/845/878cf5619901b48c69f5602da2867ded.png)

![img](https://www.pianshen.com/images/39/dbd10e0d69dfe79accad8674009159d7.JPEG)

![img](https://www.pianshen.com/images/82/8961a5b51c87a61d8d8b064fabd58e12.JPEG)

## Kafka

[Apache Kafka](http://kafka.apache.org/)

[Kafka 中文文档 - ApacheCN](https://kafka.apachecn.org/)

[Apache Kafka 基本操作_w3cschool](https://www.w3cschool.cn/apache_kafka/apache_kafka_basic_operations.html)

[《KAFKA官方文档》入门指南 | 并发编程网 – ifeve.com](http://ifeve.com/kafka-1/)

[Kafka学习之路 （一）Kafka的简介 - 扎心了，老铁 - 博客园 (cnblogs.com)](https://www.cnblogs.com/qingyunzong/p/9004509.html)

[kafka(一) - 简书 (jianshu.com)](https://www.jianshu.com/p/c54458f39a0d)

### [**简介**](http://kafka.apache.org/documentation/#introduction)

Apache的Kafka™是一个分布式流平台(*a distributed streaming platform*)。

一个流处理平台应该具有三个关键能力：

1. 它可以让你发布和订阅记录流。在这方面，它类似于一个消息队列或企业消息系统。
2. 它可以让你持久化收到的记录流，从而具有容错能力。
3. 它可以让你处理收到的记录流。

Kafka被用于两大类应用：

1. 建立实时流数据管道从而能够可靠地在系统或应用程序之间的共享数据
2. 构建实时流应用程序，能够变换或者对数据进行相应的处理。

概念：

- Kafka是运行在一个或多个服务器的集群(Cluster)上的。
- Kafka集群分类存储的记录流被称为主题(Topics)。
- 每个消息记录包含一个键，一个值和时间戳。

Kafka有四个核心API：

- [生产者 API](http://kafka.apache.org/documentation.html#producerapi) 允许应用程序发布记录流至一个或多个Kafka的话题(Topics)。
- [消费者API](http://kafka.apache.org/documentation.html#consumerapi)允许应用程序订阅一个或多个主题，并处理这些主题接收到的记录流。
- [Streams API](http://kafka.apache.org/documentation/streams)允许应用程序充当*流处理器（**stream processor**）*，从一个或多个主题获取输入流，并生产一个输出流至一个或多个的主题，能够有效地变换输入流为输出流。
- [Connector API](http://kafka.apache.org/documentation.html#connect)允许构建和运行可重用的生产者或消费者，能够把 Kafka主题连接到现有的应用程序或数据系统。例如，一个连接到关系数据库的连接器(connector)可能会获取每个表的变化。

Kafka的客户端和服务器之间的通信是靠一个简单的，高性能的，与语言无关的[TCP协议](https://kafka.apache.org/protocol.html)完成的。这个协议有不同的版本，并保持向后兼容旧版本。Kafka不光提供了一个Java客户端，还有[许多语言](https://cwiki.apache.org/confluence/display/KAFKA/Clients)版本的客户端。

### [**主题和日志**](http://kafka.apache.org/documentation/#intro_topics)

主题是一种分类或发布的一系列记录的名义上的名字。Kafka的主题始终是支持多用户订阅的; 也就是说，一个主题可以有零个，一个或多个消费者订阅写入的数据。

对于每一个主题，Kafka集群保持一个分区日志文件，看下图：

![img](http://kafka.apache.org/0102/images/log_anatomy.png)

每个分区是一个有序的，不可变的消息序列，新的消息不断追加到这个有组织的有保证的日志上。分区会给每个消息记录分配一个顺序ID号 – *偏移量，* *能够*唯一地标识该分区中的每个记录。

Kafka集群保留所有发布的记录，不管这个记录有没有被消费过，Kafka提供可配置的保留策略去删除旧数据(还有一种策略根据分区大小删除数据)。例如，如果将保留策略设置为两天，在记录公布后两天，它可用于消费，之后它将被丢弃以腾出空间。Kafka的性能跟存储的数据量的大小无关， 所以将数据存储很长一段时间是没有问题的。

![img](http://kafka.apache.org/0102/images/log_consumer.png)

事实上，保留在每个消费者元数据中的最基础的数据就是消费者正在处理的当前记录的偏移量(offset)或位置(position)。这种偏移是由消费者控制：通常偏移会随着消费者读取记录线性前进，但事实上，因为其位置是由消费者进行控制，消费者可以在任何它喜欢的位置读取记录。例如，消费者可以恢复到旧的偏移量对过去的数据再加工或者直接跳到最新的记录，并消费从“现在”开始的新的记录。

这些功能的结合意味着，实现Kafka的消费者的代价都是很小的，他们可以增加或者减少而不会对集群或其他消费者有太大影响。例如，你可以使用我们的命令行工具去追随任何主题，而且不会改变任何现有的消费者消费的记录。

数据日志的分区，一举数得。首先，它们允许数据能够扩展到更多的服务器上去。每个单独的分区的大小受到承载它的服务器的限制，但一个话题可能有很多分区，以便它能够支持海量的的数据。其次，更重要的意义是分区是进行并行处理的基础单元。

### **分布式**

日志的分区会跨服务器的分布在Kafka集群中，每个服务器会共享分区进行数据请求的处理。每个分区可以配置一定数量的副本分区提供容错能力。

每个分区都有一个服务器充当“leader”和零个或多个服务器充当“followers”。 leader处理所有的读取和写入分区的请求，而followers被动的从领导者拷贝数据。如果leader失败了，followers之一将自动成为新的领导者。每个服务器可能充当一些分区的leader和其他分区的follower，这样的负载就会在集群内很好的均衡分配。

### [**生产者**](http://kafka.apache.org/documentation/#intro_producers)

生产者发布数据到他们所选择的主题。生产者负责选择把记录分配到主题中的哪个分区。这可以使用轮询算法( round-robin)进行简单地平衡负载，也可以根据一些更复杂的语义分区算法（比如基于记录一些键值）来完成。

### [**消费者**](http://kafka.apache.org/documentation/#intro_consumers)

消费者以*消费群（**consumer group* *）*的名称来标识自己，每个发布到主题的消息都会发送给订阅了这个主题的消费群里面的一个消费者的一个实例。消费者的实例可以在单独的进程或单独的机器上。

如果所有的消费者实例都属于相同的消费群，那么记录将有效地被均衡到每个消费者实例。

如果所有的消费者实例有不同的消费群，那么每个消息将被广播到所有的消费者进程。

![img](http://kafka.apache.org/0102/images/consumer-groups.png)

两个服务器的Kafka集群具有四个分区（P0-P3）和两个消费群。A消费群有两个消费者，B群有四个。

更常见的是，我们会发现主题有少量的消费群，每一个都是“逻辑上的订阅者”。每组都是由很多消费者实例组成，从而实现可扩展性和容错性。这只不过是发布 – 订阅模式的再现，区别是这里的订阅者是一组消费者而不是一个单一的进程的消费者。

Kafka消费群的实现方式是通过分割日志的分区，分给每个Consumer实例，使每个实例在任何时间点的都可以“公平分享”独占的分区。维持消费群中的成员关系的这个过程是通过Kafka动态协议处理。如果新的实例加入该组，他将接管该组的其他成员的一些分区; 如果一个实例死亡，其分区将被分配到剩余的实例。

Kafka只保证一个分区内的消息有序，不能保证一个主题的不同分区之间的消息有序。分区的消息有序与依靠主键进行数据分区的能力相结合足以满足大多数应用的要求。但是，如果你想要保证所有的消息都绝对有序可以只为一个主题分配一个分区，虽然这将意味着每个消费群同时只能有一个消费进程在消费。

### **保证**

Kafka提供了以下一些高级别的保证：

- 由生产者发送到一个特定的主题分区的消息将被以他们被发送的顺序来追加。也就是说，如果一个消息M1和消息M2都来自同一个生产者，M1先发，那么M1将有一个低于M2的偏移，会更早在日志中出现。
- 消费者看到的记录排序就是记录被存储在日志中的顺序。
- 对于副本因子N的主题，我们将承受最多N-1次服务器故障切换而不会损失任何的已经保存的记录。

对这些保证的更多细节可以参考文档的设计部分。

### [**Kafka作为消息系统**](http://kafka.apache.org/documentation/#kafka_mq)

消息处理模型历来有两种：[队列](http://en.wikipedia.org/wiki/Message_queue)和[发布-订阅](http://en.wikipedia.org/wiki/Publish–subscribe_pattern)。在队列模型中，一组消费者可以从服务器读取记录，每个记录都会被其中一个消费者处理; 在发布-订阅模式里，记录被广播到所有的消费者。这两种模式都具有一定的优点和弱点。队列的优点是它可以让你把数据分配到多个消费者去处理，它可以让您扩展你的处理能力。不幸的是，队列不支持多个订阅者，一旦一个进程读取了数据，这个数据就会消失。发布-订阅模式可以让你广播数据到多个进程，但是因为每一个消息发送到每个订阅者，没办法对订阅者处理能力进行扩展。

Kafka的消费群的推广了这两个概念。消费群可以像队列一样让消息被一组进程处理（消费群的成员），与发布 – 订阅模式一样，Kafka可以让你发送广播消息到多个消费群。

Kafka的模型的优点是，每个主题都具有这两个属性，它可以扩展处理能力，也可以实现多个订阅者，没有必要二选一。

Kafka比传统的消息系统具有更强的消息顺序保证的能力。

传统的消息队列的消息在队列中是有序的，多个消费者从队列中消费消息，服务器按照存储的顺序派发消息。然而，尽管服务器是按照顺序派发消息，但是这些消息记录被异步传递给消费者，消费者接收到的消息也许已经是乱序的了。这实际上意味着消息的排序在并行消费中都将丢失。消息系统通常靠 “排他性消费”( exclusive consumer)来解决这个问题，只允许一个进程从队列中消费，当然，这意味着没有并行处理的能力。

Kafka做的更好。通过一个概念：并行性-分区-主题实现主题内的并行处理，Kafka是能够通过一组消费者的进程同时提供排序保证和负载均衡。每个主题的分区指定给每个消费群中的一个消费者，使每个分区只由该组中的一个消费者所消费。通过这样做，我们确保消费者是一个分区唯一的读者，从而顺序的消费数据。因为有许多的分区，所以负载还能够均衡的分配到很多的消费者实例上去。但是请注意，一个消费群的消费者实例不能比分区数量多。

### **Kafka作为存储系统**

任何消息队列都能够解耦消息的生产和消费，还能够有效地存储正在传送的消息。Kafka与众不同的是，它是一个非常好的存储系统。

Kafka把消息数据写到磁盘和备份分区。Kafka允许生产者等待返回确认，直到副本复制和持久化全部完成才认为成功，否则则认为写入服务器失败。

Kafka使用的磁盘结构很好扩展，Kafka将执行相同的策略不管你是有50 KB或50TB的持久化数据。

由于存储的重要性，并允许客户控制自己的读取位置，你可以把Kafka认为是一种特殊用途的分布式文件系统，致力于高性能，低延迟的有保障的日志存储，能够备份和自我复制。

### **Kafka流处理**

只是读，写，以及储存数据流是不够的，目的是能够实时处理数据流。

在Kafka中，流处理器是从输入的主题连续的获取数据流，然后对输入进行一系列的处理，并生产连续的数据流到输出主题。

例如，零售应用程序可能需要输入销售和出货量，根据输入数据计算出重新订购的数量和调整后的价格，然后输出到主题。

这些简单处理可以直接使用生产者和消费者的API做到。然而，对于更复杂的转换Kafka提供了一个完全集成的[流API](http://kafka.apache.org/documentation/streams)。这允许应用程序把一些重要的计算过程从流中剥离或者加入流一起。

这种设施可帮助解决这类应用面临的难题：处理杂乱的数据，改变代码去重新处理输入，执行有状态的计算等

流API建立在Kafka提供的核心基础单元之上：它使用生产者和消费者的API进行输入输出，使用Kafka存储有状态的数据，并使用群组机制在一组流处理实例中实现容错。

### **把功能组合起来**

消息的传输，存储和流处理的组合看似不寻常却是Kafka作为流处理平台的关键。

像HDFS分布式文件系统，允许存储静态文件进行批量处理。像这样的系统允许存储和处理*过去的历史数据*。

传统的企业消息系统允许处理您订阅后才抵达的消息。这样的系统只能处理将来到达的数据。

Kafka结合了这些功能，这种结合对Kafka作为流应用平台以及数据流处理的管道至关重要。

通过整合存储和低延迟订阅，流处理应用可以把过去和未来的数据用相同的方式处理。这样一个单独的应用程序，不但可以处理历史的，保存的数据，当它到达最后一条记录不会停止，继续等待处理未来到达的数据。这是泛化了的的流处理的概念，包括了批处理应用以及消息驱动的应用。

同样，流数据处理的管道结合实时事件的订阅使人们能够用Kafka实现低延迟的管道; 可靠的存储数据的能力使人们有可能使用它传输一些重要的必须保证可达的数据。可以与一个定期加载数据的线下系统集成，或者与一个因为维护长时间下线的系统集成。流处理的组件能够保证转换（处理）到达的数据。

### [**实例**](http://kafka.apache.org/documentation/#quickstart)

#### [**下载代码**](http://kafka.apache.org/documentation/#quickstart_download)

```
> tar -xzf kafka_2.11-0.10.2.0.tgz
> cd kafka_2.11-0.10.2.0
```

#### [**启动服务器**](http://kafka.apache.org/documentation/#quickstart_startserver)

Kafka使用ZooKeeper的，所以你需要先启动ZooKeeper的服务器。可以使用Kafka包装里的脚本来得到一个ZooKeeper实例。

```
> bin/zookeeper-server-start.sh config/zookeeper.properties
[2013-04-22 15:01:37,495] INFO Reading configuration from: config/zookeeper.properties (org.apache.zookeeper.server.quorum.QuorumPeerConfig)
...
```

现在启动Kafka服务器：

```
> bin/kafka-server-start.sh config/server.properties
[2013-04-22 15:01:47,028] INFO Verifying properties (kafka.utils.VerifiableProperties)
[2013-04-22 15:01:47,051] INFO Property socket.send.buffer.bytes is overridden to 1048576 (kafka.utils.VerifiableProperties)
...
```

#### [**创建一个话题**](http://kafka.apache.org/documentation/#quickstart_createtopic)

创建一个名为“test”主题，只有一个分区，只有一个副本：

```
> bin/kafka-topics.sh --create --zookeeper localhost:2181 --replication-factor 1 --partitions 1 --topic test
```

可以看到，如果运行的列表主题命令话题：

```
> bin/kafka-topics.sh --list --zookeeper localhost:2181
test
```

除了手动创建主题，你还可以配置你的代理服务器(broker)，当一个不存在的主题被发布的时候它能自动创建相应的主题。

#### [**发送一些消息**](http://kafka.apache.org/documentation/#quickstart_send)

Kafka带有一个命令行客户端，获取从文件或来自标准输入的输入，并作为消息发送到Kafka集群。默认情况下，每一行将被作为单独的消息发送。

运行生产者脚本，然后输入一些信息到控制台发送到服务器。

```
> bin/kafka-console-producer.sh --broker-list localhost:9092 --topic test
This is a message
This is another message
```

#### [**启动消费者**](http://kafka.apache.org/documentation/#quickstart_consume)

Kafka也有一个命令行消费者，将收到的消息输出到标准输出。

```
> bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
This is a message
This is another message
```

如果你在不同的终端上运行上面的命令，那么你现在应该能看到从生产者终端输入的消息会出现在消费者终端。

所有的命令行工具都有其他选项; 不带参数运行命令将显示更加详细的使用信息。

#### [**设置多代理群集**](http://kafka.apache.org/documentation/#quickstart_multibroker)

对于Kafka，一个代理是只有一个单节点的集群，因此多代理集群只是比开始多了一些代理实例外，没有什么太大的变化。

首先，做多个配置文件（在Windows上使用copy命令来代替）：

```
> cp config/server.properties config/server-1.properties
> cp config/server.properties config/server-2.properties
```

然后，编辑这些新文件的属性（此处略）。

#### [**使用Kafka连接导入/导出数据**](http://kafka.apache.org/documentation/#quickstart_kafkaconnect)

从控制台写入数据和写回控制台是一个很方便入门的例子，但你可能想用Kafka使用其他来源的数据或导出Kafka的数据到其他系统。相对于许多系统需要编写定制集成的代码，您可以使用Kafka连接到系统去导入或导出数据。

Kafka Connect是包括在Kafka中一个工具，用来导入导出数据到Kafka。它是*connectors*的一个可扩展工具，其执行定制逻辑，用于与外部系统交互。在这个快速入门，我们将看到如何使用Kafka Connect做一些简单的连接器从一个文件导入数据到Kafka的主题，和将主题数据导出到一个文件。

#### [**使用Kafka Streams处理数据**](http://kafka.apache.org/documentation/#quickstart_kafkastreams)

Kafka Streams 是Kafka的客户端库， 用来做实时流处理和分析存储在Kafka代理服务器的数据（代码略）。